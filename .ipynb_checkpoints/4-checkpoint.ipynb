{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 文章要約アプリの作成\n",
    "\n",
    "## 1週目\n",
    "\n",
    "「文章要約 API」と検索していただくと、株式会社リクルートテクノロジーズが開発した`Summpy`というAPIがヒットするかと思います。いろいろと調べてみたのですが、一般向けに公開している文章要約APIは`Summpy`が良いようなのでこちらを使っていきたいと思います。\n",
    "\n",
    "\n",
    "実際は、`Summpy`とは別の`Text Summarization API`というこれまたリクルートが公開しているAPIもあるのですが、こちらは **「1文の最大文字数は200文字、且つ最大文章数は10」** という制限があるため、Summpy使用の方向で進めていきたいと思います。\n",
    "※最大文章数１０はなかなか厳しいです\n",
    "\n",
    "`Text Summarization API`に興味のある方は[こちら](https://a3rt.recruit-tech.co.jp/product/TextSummarizationAPI/)を参考に実装してみてください。そこまで難しくないと思います。\n",
    "\n",
    "\n",
    "### Summpy使用にあたり\n",
    "\n",
    "以下の記事にてSummｐｙが初めて公開されました。  \n",
    "[自動要約APIを作ったので公開します](https://recruit-tech.co.jp/blog/2015/10/30/summpy-released/)\n",
    "\n",
    "記事のリンク先にGithubへのリンクがあったため、そちらを参考に進めていこうと考えました。  \n",
    "しかし、以下のGithubに公開されているものが`python２`で書かれており、python３で使用できない形となっております。  \n",
    "https://github.com/recruit-tech/summpy\n",
    "\n",
    "\n",
    "python3バージョンの`Summpy`のコードがないかをいろいろと検索してみたら、python3に変更してくれた方がいました。\n",
    "そちらを使用してみようと試みてみましたが、多々エラーが起こってしまいうまくいかなかったです。\n",
    "https://github.com/boarnasia/summpy\n",
    "\n",
    "\n",
    "そこで、かなり大変ではありますがpython2用の、`summpy`を用いてpython3に対応できるように修正していきます。\n",
    "\n",
    "\n",
    "\n",
    "### gitからクローンする\n",
    "\n",
    "まず、作業ディレクトリとして、`text_summary`というディレクトリを作成し、そのディレクトリ内で作業を進めていきます。\n",
    "\n",
    "`jupyter`のホームから`terminal`を開いてください。  以下のコマンドでGithubからクローンしてきましょう。  \n",
    "\n",
    "```\n",
    "git clone https://github.com/recruit-tech/summpy.git\n",
    "```\n",
    "\n",
    "`summpy`というフォルダ内に`summpy`というフォルダがあるのでややこしいですが、必要なファイルはすべて`summpy/summpy`の中にあります。\n",
    "\n",
    "不要なファイル類を削除するために以下のコマンドを打ちましょう。\n",
    "\n",
    "まず、`summpy`を`_summpy`に変更します。  \n",
    "`mv`：　ファイルを移動する際に使用するコマンド\n",
    "\n",
    "```\n",
    "mv summpy _summpy\n",
    "```\n",
    "\n",
    "次に`_summpy/summpy`の中の全てのファイルを`text_summary`に移動します。\n",
    "\n",
    "```\n",
    "mv ./_summpy/summpy ./\n",
    "```\n",
    "そして、不要なディレクトリである`_summpy`を削除しましょう。\n",
    "\n",
    "```\n",
    "rm -r -f _summpy\n",
    "```\n",
    "\n",
    "`ls`で確認し、`summpy`ディレクトリのみになっていたら成功です。\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### python2 -> python3   に変換\n",
    "\n",
    "python2とpython3の違いはいくつかありますが、このコードがpython2で書かれているのものだなと気づくときの多くが`print文`を見たときです。  \n",
    "[Python 2.7.x と 3.x の決定的な違いを例とともに](https://postd.cc/the-key-differences-between-python-2-7-x-and-python-3-x-with-examples/)\n",
    "\n",
    "- python2　：　print 'Hello World' \n",
    "- python3　：　print('Hello World' )\n",
    "\n",
    "\n",
    "上記のように、python2は`()`が存在しません。このような違いを１つずつ修正していくのは面倒だなと思ったので、\n",
    "**「python2 to python3」**と調べてみたところ`2to3`というpytho2をpython3に書き換えてくれるものが見つかったのでこちらを使っていきましょう。\n",
    "\n",
    "以下のサイトを参考に３系にコードを変換します。\n",
    "https://docs.python.jp/3/library/2to3.html\n",
    "\n",
    "以下のコードで`summpy`のフォルダ内のpythonファイルを全て３系に変換しましょう。  \n",
    "既存の２系ファイルが全て３系ファイルに書き換えられます。\n",
    "\n",
    "- -w : ファイルを変換結果に置き換える場合\n",
    "- -n : バックアップファイルが不要な場合\n",
    "- -f all : 全ての変換を適用する場合\n",
    "\n",
    "```\n",
    "2to3 -f all -n -W ./summpy/\n",
    "```\n",
    "\n",
    "![](images/text/03.png)\n",
    "\n",
    "これでPython3への変換が完了しました。\n",
    "わかりやすい目安としては、`print`文を確認すると、３系に変換されたことが確認できます。\n",
    "\n",
    "- python2：print text\n",
    "- python3：print(text)\n",
    "\n",
    "それでは、`summpy`フォルダと同階層に`python_summpy`というjupyter notebookを作成しましょう。\n",
    "\n",
    "Githubの`README.md`のやり方に沿って文章要約をしていきます！\n",
    "\n",
    "### 使用するテキストの読み込み\n",
    "\n",
    "まずは、今回要約に用いるテキストファイルを以下からダウンロードしましょう。  \n",
    "[kikagaku.txt](kikagaku.txt)\n",
    "\n",
    "このテキストは弊社の[こちら](https://www.kikagaku.co.jp/column/kikagaku-1st/)のブログ内容を使用しております。\n",
    "\n",
    "それでは早速、テキストファイルを読み込みましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('kikagaku.txt') as f:\n",
    "    text = ''.join(f.readlines())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "こちらは**自然言語**の講義にて記事ファイルを読み込む際にお伝えしました。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'本日2017年12月31日をもって、株式会社キカガクの１期目が終了します。\\n会社を創業して右も左も分からない私にとって、多くの方の支援があってこその１年でした。\\nお会い出来たみなさま、SNSで支えてくださったみなさま、本当にありがとうございます。\\n\\n明日2018年より2期目に突入し、これから更に多くの方へ貢献できるよう精進いたしますので、引き続きよろしくお願いいたします。\\n\\nそれでは、１年の締めということで、創業して１年目を振り返ります。\\n\\nこの記事はこれから会社を創業しようと思っている人に向け、そして、数年後の私に向けて書きました。\\nこれから新しいことへ挑戦される方の助けとなりますように。\\n\\n創業のはじまり\\nもともとは株式会社Caratの１事業として始まった機械学習の教育サービスであるキカガク。\\nそこから本格的にこの教育サービスをビジネスとして展開していきたいという想いから、Caratの一事業ではなく、株式会社キカガクとして法人化させ、そして、単なる教育では終わらない会社にしていこうと決めました。\\n\\n\\n『キカガク』は機械学習の略として覚えてもらいやすいように、この名前に決めましたが、それ以外にも上記のように各文字をPDCAの頭文字としています。\\n\\nキ：教育 -> 何ができるかを知ることで、機械学習を応用する場面が見えてきます\\nカ：課題設定 -> できることがわかった後にどのように実現していくかを考えます\\nガ：学習モデル構築 -> 定めた目標を達成するためのデータ解析を行います\\nク：組み込み -> 解析した結果を永続的に使用するためにシステムへの統合を行います\\nこのように、いまではキカガクが『AI教育の会社』として紹介される場面が多くありますが、会社の方針として、教育だけではなく、機械学習のPDCAを回す工程の全体をスコープとして定めました。\\n\\nちなみに、キカガクのロゴは99designsというデザイナーがコンペティション形式でデザインを競い合い、一番気に入ったものを使用できるといった新しいスタイルのサイトで作成しました。\\n* 起業家として、新しいサービスを使いながら、他の人のビジネスモデルの善し悪しの検討もよく行っていました。\\n\\n今でもこの判断は正解だったと思っています。\\n今年は１年間でオフラインの方で約１０００名、オンラインで約１５００名に指導することができました。\\nその指導した生徒の中には、実際にビジネスで活用する人も出てきており、私自身がお伝えしている『運用までを踏まえた解析の大事さ』が痛いほどよく分かると話されています。\\n\\nそういった背景から、『教科書の内容を分かりやすく噛み砕いて教えることができたとしても、現場で必要なスキルを伝えることはできない』と感じ、現場で使われている実践的な内容をカリキュラムへフィードバックしていけることを弊社の強みとしています。\\nこの『現場で使われている実践的な内容をフィードバック』するために、私自身が今年１年間で大手企業６社とコンサルティング契約を行って、現場の案件を現場の技術者の方と一緒に泥臭く進めていきました。\\nうまく進めることができる案件もあれば、技術的もしくは経営的にうまく進めることができない案件もあり、やはり『数学やプログラミングを学ぶ＝機械学習案件の導入に成功する』といったスコープの狭さではうまくいかないことを実感しました。\\n\\nしかし、『基礎なくして応用なし』であることも事実であり、創業して最初の数ヶ月間はキカガクのキである『教育』に専念することからはじめました。\\n\\n１月〜３月：ひたすら目の前のイベントをこなす日々\\n\\n京都大学大学院の修士課程を修了して、新卒入社した会社を７ヶ月で退職して起業した私にとって、研究者としてもビジネスパーソンとしても知名度は全くありませんでした。\\nしかも、生活の資金もほとんどありません。\\n\\nしかし、やる気と根拠のない自信だけはあった私にとって、がむしゃらに動き回ることは全く苦ではなく、Connpassのサイトに勉強会ページを作り、集客はそこにおまかせして、集まっていただけた方に勉強を教えるといった日々が続きました。\\nもちろんオフィスはないわけで、SpaceMarketなどの『イベントスペースを借りたい人と貸したい人』を繋ぐCtoCサービスをフル活用しながらイベントスペースを借りて、そこで勉強会を行っていました。\\nその時にできた最初のセミナーが『人工知能・機械学習 脱ブラックボックスセミナー』です。\\n\\n機械学習を専攻している自分としては最初から全自動でこのようなイベント運営をできればと思う気持ちもあったのですが、\\n『オペレーションしながら優先度が高い点が見つかり、この優先度が高いものから自動化していくほど費用対効果が高い』\\nと限られた時間の取捨選択の大事さも痛感していたため、最初はすべて一人で手動オペレーションと割り切っていました。\\n\\nちなみに、これまでエンジニアとして働いてきた私にとって、初回のセミナーでは「領収書もらえますか？」と言われた一言が衝撃的で、「そうだ、お金を受け取るということは領収書がいるのか！」とビジネスを行うには、単にサービスを提供するだけでなく、その周辺の知識もしっかりと付けておかないといけないことを自覚しました。\\n領収書はコンビニで購入して、50000円以上の場合は収入印紙を貼るなどの当たり前の知識もWebで検索して覚え、管理的には現金での受取りはあまり好ましくないとのことで、後々は銀行振込にしてもらうなど少しずつ改善していきました。\\n企業では請求書払いを好まれるケースも多く、そういうときはmisocaを使用して請求書を作成していました。\\n現在では、会社の経理にMFクラウド会計を使用していることもあり、MFクラウド請求書へと移行していきました。\\n\\n最初は世の中のニーズと一致して、特に宣伝することなく集客ができていたのですが、もちろんそれが継続することもなく、セミナーを開始して１ヶ月経った２月の後半には少しずつ人の集まりが悪くなり、これを継続的に続けていくためにはどのような施策が必要かと考えるようになりました。\\n本来であれば広告費をかけて集客するところですが、資金的にも余裕のなかった私にとって工夫して乗り切る必要がありました。\\n\\nそこで考えついたのが『キカガクNight！』\\n参加費が無料で、もし面白ければその方の意思で払う金額を決めてもらうという企画でした。\\n受ける側にも本気になってもらい、こちらも本気で応えるこの企画。\\n\\n結果は大成功。\\n\\n一気にイベントへの参加者が増え、この頃に１ヶ月で200名以上とお会いしたのが懐かしいです。\\n\\nこの企画の経緯はこちらの記事にまとめています。\\n\\n４月〜６月：念願のオフィス開設で会社らしく\\n毎回セミナーのイベント会場を抑えることが手間となり、費用対効果を考えてもそろそろオフィスの開設ができるのではないかと、オフィス開設を考え始めました。\\n本当は２月の後半から探し始めたのですが、なかなか良い物件が決まらず、仮に決まったとしても大家さんからのNGがでてしまったり、迷っているうちに他の人に契約をされてしまったりと、１ヶ月以上物件を決めることができませんでした。\\nこの時に、自分の信用力の無さを実感しました。\\n\\nそのような中、広くて間取りも良く素晴らしい場所を発見し、早速見学を申し入れ、その日に契約書も持っていき提出しました。\\n他にも見学者がいたのですが、そのスピード感で決められること、そして、その大家さんが人工知能の教育はこれから必要だと事業内容にも共感していただけたことが非常に大きな決め手でした。\\n\\nこの頃まで一人で会社の運営を行っていたのですが、イベント準備、集客、メール連絡、セミナー講義、問合せ対応、経理などひとりの仕事量に限界を感じ始めました。\\n自分で言うのも変ですが、他の人よりは同じ時間で多くのアウトプットを出すことが得意であったため、起業したての頃は他の人に期待して任せるよりも、まずは自分ひとりで歯を食いしばって頑張るべきといった持論がありました。\\nそのために、仕事術として下記のように『やらない事』もきっちりと決めて仕事をしていました。\\n\\n７月〜９月：大きな連携で一気に進展\\n今年の５月に発表され、日本中を沸かせた『Preferred Networks とマイクロソフト、ディープラーニングソリューション分野で戦略的協業』。\\nそして、この発表の中で３つの軸として『人材育成』にフォーカスが当たっています。\\n\\nこの５月の発表を前にして、Facebook Messanger経由で一通の連絡がありました。\\nなんと日本マイクロソフトの方から。\\n\\nAIで有名な日本の会社とマイクロソフトがアライアンスを進めており、そのトレーニング展開に弊社と協業したいとのご連絡でした。\\n\\nあまりにも突然の連絡であり、全く実感がわかず、まだ私一人の弊社にそんな大きな話が来るはずがないと、その連絡には返信をしていませんでした。\\n今となっては、本当にすいません m(_ _)m 汗\\n\\nしかし、その数日後、会社のお問い合わせから同じメッセージがまた一通届き、これは本当の話ではないか？と少し信じました。\\n\\nただ、自分がマイクロソフトの社員であれば、弊社に声をかけることなど、まずありえないため、どう考えても腑に落ちない。。。\\nそんな中、実際に会って話してみることにしました。\\nまず話せば良いのではと思われるかもしれませんが、私自身、会ってみると楽しくなってすぐに決めてしまう性格なので、会う前にある程度フィルタリングするように気をつけています。\\n\\n会ってみると、その場で意気投合。\\nマイクロソフト社員の方も京都大学出身ということで、懐かしい学生時代の話に花を咲かせました。\\n\\n聞いてみると、キカガクの講義の評判を聞き、声をかけていただけたそうで、地道ですが、目の前のお客様の満足度を考えた授業を精一杯頑張ってきた甲斐があったなと実感したときでした。\\n\\n間違いなく今年一番お世話になったマイクロソフトの廣野さんとの一枚\\n\\nそして、マイクロソフトの執行役員の方、そして、Preferred Networksの社長へのプレゼンを無事に終え、弊社が日本マイクロソフト・Preferred Networks公認のトレーニング企業となることができました。\\n\\nそこから、7月19日の初回セミナーに向け、企画からカリキュラム作成（PFNの方のレビューまでいただきました）、チラシ作成、現場のオペレーション整備など、人生初めての協業でわからないことだらけでしたが、多くの方に助けてもらいながら、がむしゃらに夜遅くまで働き続け、なんとか記念すべき第１回目のセミナーを迎えることができました。\\n\\nそして、その中で社員として、今西くんがジョインしてくれました。\\n彼は７月からジョインしてくれ、この１月からCLO (Chief Learning Officer)という教育事業ならではのポジションについてもらうことになるほど、この１年間頑張ってくれました。\\n\\nほんと、彼に出会え、そして彼がキカガクを選んでくれて感謝です。\\nこれからも一緒に頑張ろうね。\\n\\n９月〜１２月：怒涛のイベント登壇\\n７月からはじまったDeep Learning ハンズオンセミナーが一段落して、今西くんにセミナー講義も任せられるようになり、時間に余裕ができたため、他の人からお話を頂いていたイベント登壇やセミナー協業を進めていきました。\\n\\n自社以外で登壇させていただいたセミナー\\n・9/1：Microsoft Japan Partner Conference 『Microsoft Azure と Chainer によるディープラーニング実装ハンズオンセミナー』\\n・9/7：PyconJP2017 Chainerで学ぶディープラーニング入門\\n・9/26：株式会社ジーアングル 『AI・機械学習 × ロボットアプリの可能性』\\n・10/1：Yuxio(ゆきしお)さん主催 『データ分析・機械学習LT会』\\n・10/24：Deep Learning Lab『満足度100％ ディープラーニングハンズオンで始めるAI ビジネス』\\n・11/18：ヒューマンネットワーク高専 『日本の産業を盛り上げたい その答えは人工知能・機械学習の教育でした』\\n・12/7：リテールAI研究会 『AIビジネス活用の現状と現場で起きている問題』\\n・12/17：Chainer Beginner’s Hands-on #02 『Chainerで学ぶディープラーニング入門』\\n・12/18：東証一部上場企業役員向け 『AIビジネス活用の現状と現場で起きている問題』\\n\\nそして、この９月から１２月の間には上記のイベント登壇だけでなく、下記の３つのセミナーも増やしていきました。\\n\\n・システム自動化セミナー：機械学習を使う前にシステムを自動化するだけで解決できる案件が多いと気付き、Webシステム構築からデータ収集まで網羅した内容です。\\n・データサイエンスセミナー：データの前処理が非常に重要であるにも関わらず、なかなか『機械学習』といった枠組みではお伝えしきれない部分にフォーカスを当てた内容です。\\n・データエンジニアリングセミナー：機械学習のモデルを学習した後に運用することまで説明されているセミナーがほとんどなく、この『運用』にフォーカスを当てた内容です。\\n\\n上記のセミナーもオフラインで脱ブラックボックスセミナーを行う中で受講生からでてきた要望であり、現場の意見を取り入れたとても良い内容となりました。\\nただし、２日間のセミナー内容のカリキュラム作成は非常に大変であり、各セミナーごとに企画からセミナー開始まで約１ヶ月ずつかかり、こちらもなんとか時間がない中で合間を縫って作成し続けました。\\n\\nそして、自社セミナー以外にも他の方々と協力して面白い企画も始めました。\\n\\n・実践！機械学習\\u3000ビジネス活用講座 | 日経ビッグデータ\\n\\u3000これから求められる『橋渡し人材』を育成するための１ヶ月間のセミナーです。\\n\\n・アルゴリズム論 | G’s Academy \\n\\u3000ライブラリが充実する中、自ら考えて実装できるようになる人材を育成するための授業です。\\n従来のアルゴリズム論の内容とは異なり、これからはライブラリを駆使しながら、いかにうまくプロダクトへ組み込むかを演習形式で習得してもらいます。\\n– Pythonの基礎、アルゴリズムの高速化\\n– データの圧縮、リコメンド、最適化\\n\\n・Data Science BOOTCAMP | SOMPOホールディングス・G’s ACADEMY\\n\\u3000Fitbitや運転情報を使用して現場のデータ解析を学べる企画です。\\nメンターとして参画しており、第２回チーム発表では担当チームが優勝しました。\\n\\n・データサイエンティスト養成研修 | 京都府・SOMPOホールディングス\\n\\u3000行政にもデータ活用を進めていくべく、京都府のデータサイエンティスト養成人材に主席講師に抜擢していただきました。\\n\\n・【キカガク流】人工知能・機械学習 脱ブラックボックス講座 – 初級編 – | Udemy・ベネッセホールディングス\\n\\u3000人気講座である脱ブラックボックスセミナーをUdemy用にアレンジしました。\\nデータサイエンスで最も人気のある授業に選んでいただいています。\\n\\nそして、色々な取材もしていただきました。\\n\\n共同通信社：AIのセミナー事業に奔走\\u3000教育で実社会への橋渡しを（2017.12.7）\\nCodeIQ：Udemy人気講師、吉﨑亮介氏・堅田洋資氏が語る機械学習とデータサイエンスの最適な学習法（2017.11.20）\\nBITA デジマラボ – AI人材育成セミナーって実際どうなの？\\u3000MS,PFN監修・キカガク『ディープラーニングハンズオンセミナー』受けてみた（2017.10.23）\\n日経BigData – 「機械学習のデータはそもそも企業内にない、地道に整える企業が優位に立てる」、AI活用人材育成のキカガク吉崎社長（2017.10.20）\\n起業サプリ – 日本の産業を盛り上げて、誰もがその人らしく生きられる世界を―機械学習の啓蒙に注力する若き起業家の想い（2017.10.16）\\nLab-On – 「機械学習」の学びの場を届けたい\\u3000研究と教育とビジネスを股にかける吉崎亮介氏の挑戦（2017.10.13）\\nBuild INSIDER – 人工知能・機械学習・ディープラーニングとは？ 基礎概念まとめ（2017.9.29）\\nBUSINESS INSIDER – 「AIが仕事の相棒」の世界はリアルな現実だ（2017.9.8）\\nこのようにこの３ヶ月間、自分のセミナー運営等の仕事以外に、取材、新規企画、メンター活動などほぼ休みのない日々でしたが、非常に充実していました。\\nお話をいただいたみなさま、ありがとうございました。\\n来年からもさらに面白い企画をできるよう頑張りますので、よろしくお願いいたします。\\n\\nまとめ\\n１年前の自分からは想像もつかない１年となりました。\\n\\nただし大事にし続けたことは同じで、『目の前のお客様にどのような話をすると一番喜んでもらえるのか？』、そして、『その成果を出すために最小限の労力で実現できる方法は？』でした。\\n今でも正社員は私と今西くんの２人であり、その少ないリソースの中で、通常のセミナー運営と他社との協業をたくさん進めて行かなければいけません。\\nそのためにがむしゃらに頑張るのではなく、『考えながら走り続けること』が最も大事でした。\\n\\n企画は走り始めなければ始まらない。\\nでもがむしゃらに走り続けると体力不足で倒れてしまう。\\nそのためにも、まずは身軽に走り出すけれども、その走り方には工夫をして、体力を持続しながら走り続ける。\\nそんなことを毎日毎日考えていた１年でした。\\n\\n来年もたくさんの企画を仕込んでおり、さらに大きくなれる一年にしていきます。\\n社員も増えます。\\n責任も増します。\\n日本の産業を自分たちなら盛り上げられると信じ、来年からも貪欲に取り組んでいきます。\\n\\n最後になりましたが、みなさま、本年は大変お世話になりました。\\nそして、2018年も引き続き、株式会社キカガクをどうぞよろしくお願いいたします。\\n\\n良いお年を。\\n\\n株式会社キカガク\\u3000代表取締役社長\\n吉崎 亮介'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7953"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7953文字と長めの文章です。\n",
    "\n",
    "### 文章要約の実装\n",
    "\n",
    "文章要約のメインが`summpy/lexrank.py`の中の`summarize`にあたるので、そちらを読み込みましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'networkx.utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-e7ebe72e4fff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msummpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlexrank\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msummarize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/jupyter/text_summary/summpy/lexrank.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnetworkx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDictVectorizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpairwise_distances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/networkx/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;31m# These are import orderwise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnetworkx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnetworkx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnetworkx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'networkx.utils'"
     ]
    }
   ],
   "source": [
    "from summpy.lexrank import summarize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上記のように読み込もうとするとエラーが起きてしまいますが、これは `networkx`をインストールしていないことが原因のため、`networkx`をインストールしましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting networkx\n",
      "  Downloading https://files.pythonhosted.org/packages/11/42/f951cc6838a4dff6ce57211c4d7f8444809ccbe2134179950301e5c4c83c/networkx-2.1.zip (1.6MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.6MB 494kB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: decorator>=4.1.0 in /usr/local/lib/python3.6/site-packages (from networkx)\n",
      "Building wheels for collected packages: networkx\n",
      "  Running setup.py bdist_wheel for networkx ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/44/c0/34/6f98693a554301bdb405f8d65d95bbcd3e50180cbfdd98a94e\n",
      "Successfully built networkx\n",
      "Installing collected packages: networkx\n",
      "Successfully installed networkx-2.1\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 10.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install networkx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "それでは、もう一度読み込みます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from summpy.lexrank import summarize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "特にエラーがおきていなければ成功です。では、引き続き`README.md`通りに進めて文章要約を行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "in method 'Tagger_parseToNode', argument 2 of type 'char const *'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-467293538e57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m sentences, debug_info = summarize(\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontinuous\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m )\n",
      "\u001b[0;32m/home/jupyter/text_summary/summpy/lexrank.py\u001b[0m in \u001b[0;36msummarize\u001b[0;34m(text, sent_limit, char_limit, imp_require, debug, **lexrank_params)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0mdebug_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msent_splitter_ja\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m     \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msim_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlexrank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mlexrank_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m     \u001b[0msum_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0macc_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jupyter/text_summary/summpy/lexrank.py\u001b[0m in \u001b[0;36mlexrank\u001b[0;34m(sentences, continuous, sim_threshold, alpha, use_divrank, divrank_alpha)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0msent_tf_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_segmenter_ja\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0mtf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0msent_tf_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jupyter/text_summary/summpy/misc/mecab_segmenter.py\u001b[0m in \u001b[0;36mword_segmenter_ja\u001b[0;34m(sent, node_filter, node2word, mecab_encoding)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     nodes = list(\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0m_mecab_node2seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_mecab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparseToNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmecab_encoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmecab_encoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     )\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnode_filter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/MeCab.py\u001b[0m in \u001b[0;36mparseToNode\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0m__repr__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_swig_repr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0m_MeCab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTagger_parse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mparseToNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0m_MeCab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTagger_parseToNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparseNBest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0m_MeCab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTagger_parseNBest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparseNBestInit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0m_MeCab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTagger_parseNBestInit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: in method 'Tagger_parseToNode', argument 2 of type 'char const *'"
     ]
    }
   ],
   "source": [
    "sentences, debug_info = summarize(\n",
    "    text, sent_limit=5, continuous=True, debug=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "python3への変換を完了したのでしっかり実装できるかと思ったのですが、そう簡単には実装できないようです。  \n",
    "エラー文をみてみると、`MeCab`のエラーのようです。  \n",
    "\n",
    "Google検索で`「in method 'Tagger_parseToNode', argument 2 of type 'char const *'」`と調べると、MeCabで`Tagger`を読み込んだ後に一度空文字でパースしてあげると良いようです。\n",
    "\n",
    "【参考記事】\n",
    "https://shogo82148.github.io/blog/2015/12/20/mecab-in-python3-final/\n",
    "https://teratail.com/questions/88592\n",
    "\n",
    "以下画像の赤下線のファイルでエラーが起きているので、上から順にたどっていきます。上から3番目の`text_summary/summpy/misc/mecab_segmenter.py`ファイル`67行目`の関数を実行したタイミングで`MeCab`のエラーが起きていることを確認できます。\n",
    "\n",
    "![](images/text/04.png)\n",
    "\n",
    "\n",
    "そこで、`text_summary/summpy/misc/mecab_segmenter.py`ファイルを開くと、8行目でTaggerを読み込んでいる部分があるので、9行目に以下の1行を入れて保存しましょう。\n",
    "```\n",
    "_mecab = MeCab.Tagger()\n",
    "_mecab.parse('') #追記\n",
    "```\n",
    "\n",
    "\n",
    "それでは、もう一度実行したいところなのですが、ここで1点注意点があります。\n",
    "pythonファイルを書き換えた後、JupyterNotebook上でもう一度`import`してもうまく反映されないことが多々あります。そのため少し面倒ですが、`python_summpy`を一度シャットダウンしてから再度開き、実行しましょう。  \n",
    "※上記のシャットダウン→実行の流れは今後、ファイル内のコード変更のたびに行って下さい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "in method 'Tagger_parseToNode', argument 2 of type 'char const *'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-467293538e57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m sentences, debug_info = summarize(\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontinuous\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m )\n",
      "\u001b[0;32m/home/jupyter/text_summary/summpy/lexrank.py\u001b[0m in \u001b[0;36msummarize\u001b[0;34m(text, sent_limit, char_limit, imp_require, debug, **lexrank_params)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0mdebug_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msent_splitter_ja\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m     \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msim_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlexrank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mlexrank_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m     \u001b[0msum_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0macc_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jupyter/text_summary/summpy/lexrank.py\u001b[0m in \u001b[0;36mlexrank\u001b[0;34m(sentences, continuous, sim_threshold, alpha, use_divrank, divrank_alpha)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0msent_tf_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_segmenter_ja\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0mtf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0msent_tf_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jupyter/text_summary/summpy/misc/mecab_segmenter.py\u001b[0m in \u001b[0;36mword_segmenter_ja\u001b[0;34m(sent, node_filter, node2word, mecab_encoding)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     nodes = list(\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0m_mecab_node2seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_mecab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparseToNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmecab_encoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmecab_encoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m     )\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnode_filter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/MeCab.py\u001b[0m in \u001b[0;36mparseToNode\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0m__repr__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_swig_repr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0m_MeCab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTagger_parse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mparseToNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0m_MeCab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTagger_parseToNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparseNBest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0m_MeCab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTagger_parseNBest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparseNBestInit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0m_MeCab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTagger_parseNBestInit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: in method 'Tagger_parseToNode', argument 2 of type 'char const *'"
     ]
    }
   ],
   "source": [
    "sentences, debug_info = summarize(\n",
    "    text, sent_limit=5, continuous=True, debug=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "変更してもなお同じエラーが起きてしまいます。どの記事もたいてい同じような解決策が書いてあり、参考にならなそうです。  \n",
    "そこで、大変ではありますが原因追求のため、試行錯誤していきたいと思います。\n",
    "※私がどのような手順で解決していったのか流れを書いていきます。\n",
    "\n",
    "\n",
    "#### 試行錯誤１\n",
    "\n",
    "`parseToNode(self, *args)`というMeCabの関数を呼び出したタイミングでエラーが起きているので、関数実行時に渡している引数がなにかおかしいではないかと考えてみます。つまり、`mecab_segmenter.py`68行目にある`sent`という変数に問題がないかを確認していきます。\n",
    "\n",
    "以下のように`for文`の前後で`sent`の方を確認します。  \n",
    "\n",
    "`mecab_segmenter.py`\n",
    "![](images/text/07.png)\n",
    "  \n",
    "それでは、再起動し実行しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "<class 'bytes'>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in method 'Tagger_parseToNode', argument 2 of type 'char const *'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-467293538e57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m sentences, debug_info = summarize(\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontinuous\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m )\n",
      "\u001b[0;32m/home/jupyter/text_summary/summpy/lexrank.py\u001b[0m in \u001b[0;36msummarize\u001b[0;34m(text, sent_limit, char_limit, imp_require, debug, **lexrank_params)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0mdebug_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msent_splitter_ja\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m     \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msim_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlexrank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mlexrank_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m     \u001b[0msum_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0macc_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jupyter/text_summary/summpy/lexrank.py\u001b[0m in \u001b[0;36mlexrank\u001b[0;34m(sentences, continuous, sim_threshold, alpha, use_divrank, divrank_alpha)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0msent_tf_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_segmenter_ja\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0mtf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0msent_tf_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jupyter/text_summary/summpy/misc/mecab_segmenter.py\u001b[0m in \u001b[0;36mword_segmenter_ja\u001b[0;34m(sent, node_filter, node2word, mecab_encoding)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     nodes = list(\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0m_mecab_node2seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_mecab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparseToNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmecab_encoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmecab_encoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m     )\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnode_filter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/MeCab.py\u001b[0m in \u001b[0;36mparseToNode\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0m__repr__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_swig_repr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0m_MeCab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTagger_parse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mparseToNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0m_MeCab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTagger_parseToNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparseNBest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0m_MeCab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTagger_parseNBest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparseNBestInit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0m_MeCab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTagger_parseNBestInit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: in method 'Tagger_parseToNode', argument 2 of type 'char const *'"
     ]
    }
   ],
   "source": [
    "sentences, debug_info = summarize(\n",
    "    text, sent_limit=5, continuous=True, debug=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "出力を確認してみると、`if文`の前が`str型` でif文内にてエンコードされた関係で、`bytes型`になっています。\n",
    "\n",
    "```\n",
    "<class 'str'>\n",
    "<class 'bytes'>\n",
    "```\n",
    "\n",
    "pythonの`str型`と`bytes型`の違いについては以下の記事をご覧ください。  \n",
    "https://www.kannon.link/fuku/index.php/2017/02/22/01-34/\n",
    "\n",
    "#### 試行錯誤2\n",
    "\n",
    "ここで私は「`str型`のままではダメなのかな？」と疑問に思ったので、`if文`をコメントアウトしてみます。\n",
    "\n",
    "![](images/text/08.png)\n",
    "\n",
    "もう一度実行してみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "<class 'str'>\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'decode'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-467293538e57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m sentences, debug_info = summarize(\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontinuous\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m )\n",
      "\u001b[0;32m/home/jupyter/text_summary/summpy/lexrank.py\u001b[0m in \u001b[0;36msummarize\u001b[0;34m(text, sent_limit, char_limit, imp_require, debug, **lexrank_params)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0mdebug_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msent_splitter_ja\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m     \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msim_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlexrank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mlexrank_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m     \u001b[0msum_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0macc_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jupyter/text_summary/summpy/lexrank.py\u001b[0m in \u001b[0;36mlexrank\u001b[0;34m(sentences, continuous, sim_threshold, alpha, use_divrank, divrank_alpha)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0msent_tf_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_segmenter_ja\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0mtf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0msent_tf_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jupyter/text_summary/summpy/misc/mecab_segmenter.py\u001b[0m in \u001b[0;36mword_segmenter_ja\u001b[0;34m(sent, node_filter, node2word, mecab_encoding)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     nodes = list(\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0m_mecab_node2seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_mecab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparseToNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmecab_encoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmecab_encoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m     )\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnode_filter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jupyter/text_summary/summpy/misc/mecab_segmenter.py\u001b[0m in \u001b[0;36m_mecab_node2seq\u001b[0;34m(node, decode_surface, feat_dict, mecab_encoding)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdecode_surface\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_surface\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msurface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmecab_encoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfeat_dict\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# 品詞の情報をdictで保存\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             node.feat_dict = _mecab_parse_feat(\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'decode'"
     ]
    }
   ],
   "source": [
    "sentences, debug_info = summarize(\n",
    "    text, sent_limit=5, continuous=True, debug=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 試行錯誤3\n",
    "\n",
    "実行してみると違うエラーが出てきました。もしかしたら一歩前進したかもしれません。今度のエラー`'str' object has no attribute 'decode'`は「`str型`は`decode`できませんよ」というエラー内容です。  \n",
    "そのため、`mecab_segmenter.py`23行目と26行目の`.decode()`の部分を消してしまいましょう。\n",
    "先程の`print文`2つも削除しておきましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "__next__",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-467293538e57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m sentences, debug_info = summarize(\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontinuous\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m )\n",
      "\u001b[0;32m/home/jupyter/text_summary/summpy/lexrank.py\u001b[0m in \u001b[0;36msummarize\u001b[0;34m(text, sent_limit, char_limit, imp_require, debug, **lexrank_params)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0mdebug_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msent_splitter_ja\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m     \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msim_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlexrank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mlexrank_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m     \u001b[0msum_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0macc_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jupyter/text_summary/summpy/lexrank.py\u001b[0m in \u001b[0;36mlexrank\u001b[0;34m(sentences, continuous, sim_threshold, alpha, use_divrank, divrank_alpha)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0msent_tf_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_segmenter_ja\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0mtf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0msent_tf_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jupyter/text_summary/summpy/misc/mecab_segmenter.py\u001b[0m in \u001b[0;36mword_segmenter_ja\u001b[0;34m(sent, node_filter, node2word, mecab_encoding)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     nodes = list(\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0m_mecab_node2seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_mecab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparseToNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmecab_encoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmecab_encoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m     )\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnode_filter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jupyter/text_summary/summpy/misc/mecab_segmenter.py\u001b[0m in \u001b[0;36m_mecab_node2seq\u001b[0;34m(node, decode_surface, feat_dict, mecab_encoding)\u001b[0m\n\u001b[1;32m     27\u001b[0m             )\n\u001b[1;32m     28\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__next__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/MeCab.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0m__setattr__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_swig_setattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0m__swig_getmethods__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m     \u001b[0m__getattr__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_swig_getattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No constructor defined\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0m__repr__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_swig_repr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/MeCab.py\u001b[0m in \u001b[0;36m_swig_getattr\u001b[0;34m(self, class_type, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclass_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__swig_getmethods__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_swig_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: __next__"
     ]
    }
   ],
   "source": [
    "sentences, debug_info = summarize(\n",
    "    text, sent_limit=5, continuous=True, debug=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 試行錯誤4\n",
    "\n",
    "また違うエラーが出てきました。`「AttributeError: __next__」`とGoogleで調べていただくと、\n",
    "pythonには、**generatorクラス**というものがあり、その中のメソッドに`next`があるみたいです。\n",
    "\n",
    "【参考記事】  \n",
    "https://qiita.com/yuragawa/items/b2022b534633114207e9　<br/>\n",
    "https://stackoverflow.com/questions/12274606/theres-no-next-function-in-a-yield-generator-in-python-3\n",
    "\n",
    "\n",
    "上記の記事などを参考に以下のパターンを試してみました。\n",
    "\n",
    "- .next()\n",
    "- .\\__next\\__()\n",
    "- next(node)\n",
    "- .next\n",
    "\n",
    "今回は`node = node.__next__`ではなく、`node = node.next`にしたほうが良いみたいです。\n",
    "\n",
    "`mecab_segmenter.py`29行目を変更しましょう。\n",
    "\n",
    "![](images/text/11.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "add_edge() takes 3 positional arguments but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-467293538e57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m sentences, debug_info = summarize(\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontinuous\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m )\n",
      "\u001b[0;32m/home/jupyter/text_summary/summpy/lexrank.py\u001b[0m in \u001b[0;36msummarize\u001b[0;34m(text, sent_limit, char_limit, imp_require, debug, **lexrank_params)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0mdebug_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msent_splitter_ja\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m     \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msim_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlexrank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mlexrank_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m     \u001b[0msum_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0macc_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jupyter/text_summary/summpy/lexrank.py\u001b[0m in \u001b[0;36mlexrank\u001b[0;34m(sentences, continuous, sim_threshold, alpha, use_divrank, divrank_alpha)\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msim_mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcontinuous\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_edge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'weight'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mranker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mranker_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: add_edge() takes 3 positional arguments but 4 were given"
     ]
    }
   ],
   "source": [
    "sentences, debug_info = summarize(\n",
    "    text, sent_limit=5, continuous=True, debug=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 試行錯誤5\n",
    "\n",
    "また違うエラーが出てきました。。。\n",
    "先程までと同様にGoogleで調べてみると[こちら](https://github.com/ewels/MultiQC/issues/592)の記事に以下のような記述がありました。\n",
    "```\n",
    "pip install networkx==1.11\n",
    "pip install multiqc==1.2\n",
    "```\n",
    "\n",
    "もしかしたら`networkx`と`multiqc`というライブラリのバージョンが違うのではないかと思い、確認してみました。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'multiqc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-57e9f7a1aa73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnetworkx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmultiqc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'multiqc'"
     ]
    }
   ],
   "source": [
    "import networkx\n",
    "import multiqc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "networkx.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`networkx`のバージョンは記事とは異なり、`multiqc`はインストールされていなかったです。  \n",
    "そこで`networkx`をアンインストール後、バージョン指定で再インストール、`multiqc`はバージョン指定でインストールしてみます。\n",
    "以下のコマンドをターミナル打ちましょう。\n",
    "```bash\n",
    "pip uninstall networkx\n",
    "pip install networkx==1.11\n",
    "pip install multiqc==1.2\n",
    "```\n",
    "\n",
    "シャットダウンし、もう一度実行してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences, debug_info = summarize(\n",
    "    text, sent_limit=5, continuous=True, debug=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "ようやくエラーが起こることなく通りました！！\n",
    "\n",
    "最後まで実装しましょう！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "その時にできた最初のセミナーが『人工知能・機械学習 脱ブラックボックスセミナー』です。\n",
      "そこから、7月19日の初回セミナーに向け、企画からカリキュラム作成（PFNの方のレビューまでいただきました）、チラシ作成、現場のオペレーション整備など、人生初めての協業でわからないことだらけでしたが、多くの方に助けてもらいながら、がむしゃらに夜遅くまで働き続け、なんとか記念すべき第１回目のセミナーを迎えることができました。\n",
      "７月からはじまったDeep Learning ハンズオンセミナーが一段落して、今西くんにセミナー講義も任せられるようになり、時間に余裕ができたため、他の人からお話を頂いていたイベント登壇やセミナー協業を進めていきました。\n",
      "上記のセミナーもオフラインで脱ブラックボックスセミナーを行う中で受講生からでてきた要望であり、現場の意見を取り入れたとても良い内容となりました。\n",
      "ただし、２日間のセミナー内容のカリキュラム作成は非常に大変であり、各セミナーごとに企画からセミナー開始まで約１ヶ月ずつかかり、こちらもなんとか時間がない中で合間を縫って作成し続けました。\n"
     ]
    }
   ],
   "source": [
    "for sent in sentences:\n",
    "    print(sent.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "実際に5つの文章で要約されましたが、いかがでしょうか。  個人的には今回の記事の中でも重要な文章をいくつか抜粋してきてくれているなと感じています。\n",
    "すべての文章がうまく抜粋できているわけではないですが、記事の概要をざっとつかめるような結果となっています。\n",
    "\n",
    "5つの文ではなく、もう少し文章数を増やしたり減らしたりしたら結果がどう変わるかも考察してみてください！  \n",
    "もしかしたら要約に適切な文章数が見つけられるかもしれません。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2週目\n",
    "\n",
    "### 英文要約を行おう\n",
    "\n",
    "先週は日本語要約として`summpy`についてお伝えしました。今週最初は英文における文章要約です。英語の文章要約は`summa-textrank`というものを使用しましょう。以下のGithubを参考に進めていきます。  \n",
    "https://github.com/summanlp/textrank\n",
    "\n",
    "#### ライブラリのインストール"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting summa\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/11/2be56c3740268f9a6e2379a74ffd624c5c0237c4b54093b48a7de8325987/summa-1.0.0.tar.gz (46kB)\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 299kB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy>=0.19 in /usr/local/lib/python3.6/site-packages (from summa) (0.19.1)\n",
      "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/site-packages (from scipy>=0.19->summa) (1.13.1)\n",
      "Building wheels for collected packages: summa\n",
      "  Running setup.py bdist_wheel for summa ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/25/2f/c3/8a1c472fe90aa34c8d0dff5284f56af073121bded69fefcea7\n",
      "Successfully built summa\n",
      "\u001b[31mcolormath 3.0.0 has requirement networkx>=2.0, but you'll have networkx 1.11 which is incompatible.\u001b[0m\n",
      "Installing collected packages: summa\n",
      "\u001b[33m  The script textrank is installed in '/root/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "Successfully installed summa-1.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install summa --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 使用する英文\n",
    "\n",
    "今回は以下の記事を使用していきましょう。  \n",
    "https://www.japantimes.co.jp/sports/2018/06/20/soccer/early-present-helps-japan-claim-perfect-start-world-cup-campaign/\n",
    "\n",
    "[こちら](english.txt)が上記の英文をテキストファイルにしたものになります。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('english.txt', encoding='utf-8') as f:\n",
    "    text = ''.join(f.readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An opening win that few saw coming has given Japan the perfect start to its World Cup campaign, but there will be further hurdles to clear if the team is to book its place in the knockout round.\n",
      "\n",
      "Japan beat Colombia 2-1 in Saransk on Tuesday in a game of high drama, indelibly shaped by a third-minute handball that saw Colombian midfielder Carlos Sanchez sent off and Shinji Kagawa give Japan the lead from the penalty spot. Colombia clawed its way back to equalize through Juan Quintero’s 39th-minute free kick, but Japan regrouped at halftime and a Yuya Osako header in the 73rd minute gave the Samurai Blue a historic victory.\n",
      "\n",
      "No Asian team had previously beaten a South American opponent at the World Cup, and few would have predicted that this Japan side would be the one to do it. Results had been poor heading into the tournament, and the Japan Football Association’s decision to replace manager Vahid Halilhodzic with Akira Nishino in April was beginning to look questionable at best.\n",
      "\n",
      "But Nishino and his players fully deserve their moment after a thoroughly impressive second-half performance against Colombia, and they can now have legitimate ambitions of claiming a place in the second round with games against Senegal and Poland still to come.\n",
      "\n",
      "“Every player has doubts about whether they can perform going into the tournament,” wrote former national team defender Yutaka Akita in Wednesday’s Nikkan Sports. “But I think today’s win will have blown those worries away. I believe that they can write a new page in history with Nishino at the helm.”\n",
      "\n",
      "Fortune was certainly in Japan’s favor at Mordovia Arena. First, Colombian playmaker James Rodriguez, who almost single-handedly dismantled Japan during a 4-1 win for the South Americans at the 2014 World Cup, was deemed fit enough only to start on the bench. Then Sanchez blocked Osako’s goal-bound shot with his arm to leave the Colombians a man down with 87 minutes remaining, and Kagawa gratefully dispatched the penalty.\n",
      "\n",
      "Throughout the rest of the first half, however, Japan failed to capitalize on its early present. Takashi Inui and Osako both missed chances that would have surely put the result beyond doubt by halftime, and instead Colombia was allowed to come back into the game and head into the break on level terms.\n",
      "\n",
      "“When the opposition lost a man after only three minutes, you thought ‘we can win this,’ ” wrote former Nadeshiko Japan manager Norio Sasaki in Wednesday’s Sports Nippon. “But actually the team became unsettled. It was a situation that they hadn’t anticipated. So even though they had a numerical advantage, they panicked. They hit meaningless long balls, switched sides and defended too deep, destroying their balance.”\n",
      "\n",
      "Fortunately for Japan, things picked up significantly in the second half. The team played with far greater aggression and composure in both attack and defense, and the way Osako took his goal — rising above the Colombian defense to head home a corner — typified the change in attitude.\n",
      "\n",
      "Nishino deserves huge credit for the team’s second-half improvement, and a series of canny substitutions further proved the manager’s mettle.\n",
      "\n",
      "“Nishino really proved his ability in getting Japan ready for this first game,” wrote former national team striker Akihiro Nagashima in Wednesday’s Nikkan Sports. “He’s only had a short time in the job, but he’s got the defense working as a unit, and when he brought on (Hotaru) Yamaguchi for (Gaku) Shibasaki and (Shinji) Okazaki for Osako, there was no drop-off in the way the team functioned.”\n",
      "\n",
      "Taking three points from the opening game is undoubtedly a huge advantage for teams at the World Cup, but Japan’s progress to the knockout round is far from assured just yet. Senegal proved it will be a force to be reckoned with after beating Poland 2-1 later on Tuesday, and the Poles and Colombia are by no means out of the reckoning despite their opening losses.\n",
      "\n",
      "“It’s great that the team won, but it wasn’t a controlled victory,” wrote firebrand critic Sergio Echigo in Wednesday’s Nikkan Sports. “They won because they got a penalty and the opposition had a player sent off early in the match. It’s important to analyze things with a clear head and not just celebrate.”\n",
      "\n",
      "After the way Nishino and his players suffered in the buildup to the tournament, however, it would take a heart of stone to deny them their moment.\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "まずは、インポートしましょう！`summa.summarizer`の中の`summarize`という関数を使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from summa.summarizer import summarize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`summa`は`summpy`と違い、`〇文`で文章要約するのではなく、`○単語`以内で要約する形となっております。今回は**50単語**以内で要約してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'“Nishino really proved his ability in getting Japan ready for this first game,” wrote former national team striker Akihiro Nagashima in Wednesday’s Nikkan Sports.\\nTaking three points from the opening game is undoubtedly a huge advantage for teams at the World Cup, but Japan’s progress to the knockout round is far from assured just yet.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#50単語以内での要約\n",
    "summarize(text, words=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "デフォルトで英語の要約となっていますが、引数`language='english'`の部分を`spanish`に変更すればスペイン後の要約も可能。 　　\n",
    "また、以下のように文ごとに`split`することも可能です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['“Nishino really proved his ability in getting Japan ready for this first game,” wrote former national team striker Akihiro Nagashima in Wednesday’s Nikkan Sports.',\n",
       " 'Taking three points from the opening game is undoubtedly a huge advantage for teams at the World Cup, but Japan’s progress to the knockout round is far from assured just yet.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#50単語以内での要約\n",
    "summarize(text, words=50,  split=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "英語なのでしっかりと要約できているのか定かではないですが、上記の様に非常に簡単に英語の文章要約をすることが可能です。\n",
    "\n",
    "#### 補足（キーワード抽出）\n",
    "\n",
    "`summa`を用いると以下のようにキーワード抽出も行ってくれます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from summa import keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "japan\n",
      "team\n",
      "teams\n",
      "minute\n",
      "minutes\n",
      "osako\n",
      "nishino\n",
      "colombia\n",
      "wrote\n",
      "heading\n",
      "head\n",
      "manager\n",
      "colombian\n",
      "colombians\n",
      "opening\n",
      "victory\n",
      "half\n",
      "things\n",
      "american\n",
      "americans\n",
      "sports\n",
      "greater\n",
      "fortune\n",
      "fortunately\n",
      "cup\n",
      "second\n",
      "deserves huge\n",
      "players\n",
      "player\n",
      "round\n",
      "beat\n",
      "beating\n",
      "deserve\n",
      "sanchez\n",
      "present\n",
      "takashi\n",
      "drama indelibly\n",
      "goal\n",
      "gratefully\n",
      "shinji\n",
      "switched\n",
      "meaningless\n",
      "kagawa\n"
     ]
    }
   ],
   "source": [
    "print(keywords.keywords(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "#### 問題\n",
    "今回の`summa`を用いた文章要約では以下の言語に対応しておりますが、下記の**対応言語**はどこを探せば見つかるでしょうか。\n",
    "\n",
    "##### 対応言語\n",
    "- danish（デンマーク語）\n",
    "- dutch（オランダ語）\n",
    "- english（英語）\n",
    "- finnish（フィンランド語）\n",
    "- french（フランス語）\n",
    "- german（ドイツ語）\n",
    "- hungarian（ハンガリー語）\n",
    "- italian（イタリア語）\n",
    "- norwegian（ノルウェー語）\n",
    "- porter（不明）\n",
    "- portuguese（ポルトガル語）\n",
    "- romanian（ルーマニア語）\n",
    "- russian（ロシア語）\n",
    "- spanish（スペイン語）\n",
    "- swedish（スウェーデン語）\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 回答\n",
    "\n",
    "`README.md`を確認すれば簡単に見つかりました。。。\n",
    "\n",
    "私はてっきり書いていないものだと思いこんでいたため以下のように探しました。ご参考までに。\n",
    "\n",
    "\n",
    "\n",
    "まずは、`summarize()`関数にて`language`という引数を取っているため、`summa > summarizer > summarize`を確認しましょう。その次に、以下の順番で引数`language`が使用されている関数をたどっていくと必要とする情報にたどり着きます。\n",
    "\n",
    "\n",
    "- preprocessing　> textcleaner > clean_text_by_sentences\n",
    "- preprocessing　> textcleaner > init_textcleanner\n",
    "- preprocessing　> textcleaner > set_stemmer_language\n",
    "\n",
    "\n",
    "`summa > preprocessing > textcleaner.py`の`43〜49行目`に以下のような記述部分があります。以下を確認することで、先程の**対応言語**を見つけることができました。\n",
    "```python\n",
    "def set_stemmer_language(language):\n",
    "    global STEMMER\n",
    "    if not language in LANGUAGES:\n",
    "        raise ValueError(\"Valid languages are danish, dutch, english, finnish,\" +\n",
    "                 \" french, german, hungarian, italian, norwegian, porter, portuguese,\" +\n",
    "                 \"romanian, russian, spanish, swedish\")\n",
    "    STEMMER = SnowballStemmer(language)\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 日本語文と英文に対応できる関数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に、入ってくるテキストが**日本語**か**英語**かによって場合分けするような関数を作成しましょう。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 英語と日本語の場合分け\n",
    "まずは、英語か日本語かを場合分けするような`if文`を作成する必要があります。先程読み込んだ英文を`text_english`、先週使用した`kikagkau.txt`を`text_japananese`という変数にしておきましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'An opening win that few saw coming has given Japan the perfect start to its World Cup campaign, but there will be further hurdles to clear if the team is to book its place in the knockout round.\\n\\nJapan beat Colombia 2-1 in Saransk on Tuesday in a game of high drama, indelibly shaped by a third-minute handball that saw Colombian midfielder Carlos Sanchez sent off and Shinji Kagawa give Japan the lead from the penalty spot. Colombia clawed its way back to equalize through Juan Quintero’s 39th-minute free kick, but Japan regrouped at halftime and a Yuya Osako header in the 73rd minute gave the Samurai Blue a historic victory.\\n\\nNo Asian team had previously beaten a South American opponent at the World Cup, and few would have predicted that this Japan side would be the one to do it. Results had been poor heading into the tournament, and the Japan Football Association’s decision to replace manager Vahid Halilhodzic with Akira Nishino in April was beginning to look questionable at best.\\n\\nBut Nishino and his players fully deserve their moment after a thoroughly impressive second-half performance against Colombia, and they can now have legitimate ambitions of claiming a place in the second round with games against Senegal and Poland still to come.\\n\\n“Every player has doubts about whether they can perform going into the tournament,” wrote former national team defender Yutaka Akita in Wednesday’s Nikkan Sports. “But I think today’s win will have blown those worries away. I believe that they can write a new page in history with Nishino at the helm.”\\n\\nFortune was certainly in Japan’s favor at Mordovia Arena. First, Colombian playmaker James Rodriguez, who almost single-handedly dismantled Japan during a 4-1 win for the South Americans at the 2014 World Cup, was deemed fit enough only to start on the bench. Then Sanchez blocked Osako’s goal-bound shot with his arm to leave the Colombians a man down with 87 minutes remaining, and Kagawa gratefully dispatched the penalty.\\n\\nThroughout the rest of the first half, however, Japan failed to capitalize on its early present. Takashi Inui and Osako both missed chances that would have surely put the result beyond doubt by halftime, and instead Colombia was allowed to come back into the game and head into the break on level terms.\\n\\n“When the opposition lost a man after only three minutes, you thought ‘we can win this,’ ” wrote former Nadeshiko Japan manager Norio Sasaki in Wednesday’s Sports Nippon. “But actually the team became unsettled. It was a situation that they hadn’t anticipated. So even though they had a numerical advantage, they panicked. They hit meaningless long balls, switched sides and defended too deep, destroying their balance.”\\n\\nFortunately for Japan, things picked up significantly in the second half. The team played with far greater aggression and composure in both attack and defense, and the way Osako took his goal — rising above the Colombian defense to head home a corner — typified the change in attitude.\\n\\nNishino deserves huge credit for the team’s second-half improvement, and a series of canny substitutions further proved the manager’s mettle.\\n\\n“Nishino really proved his ability in getting Japan ready for this first game,” wrote former national team striker Akihiro Nagashima in Wednesday’s Nikkan Sports. “He’s only had a short time in the job, but he’s got the defense working as a unit, and when he brought on (Hotaru) Yamaguchi for (Gaku) Shibasaki and (Shinji) Okazaki for Osako, there was no drop-off in the way the team functioned.”\\n\\nTaking three points from the opening game is undoubtedly a huge advantage for teams at the World Cup, but Japan’s progress to the knockout round is far from assured just yet. Senegal proved it will be a force to be reckoned with after beating Poland 2-1 later on Tuesday, and the Poles and Colombia are by no means out of the reckoning despite their opening losses.\\n\\n“It’s great that the team won, but it wasn’t a controlled victory,” wrote firebrand critic Sergio Echigo in Wednesday’s Nikkan Sports. “They won because they got a penalty and the opposition had a player sent off early in the match. It’s important to analyze things with a clear head and not just celebrate.”\\n\\nAfter the way Nishino and his players suffered in the buildup to the tournament, however, it would take a heart of stone to deny them their moment.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_english = text\n",
    "text_english"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "日本語は前回使用したテキストを使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('kikagaku.txt', encoding='utf-8') as f:\n",
    "    text_japanese = ''.join(f.readlines())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "日本語かどうかの判定を`Unicode` の違いによって条件分岐を行っています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "\n",
    "def is_japanese(text):\n",
    "    for _text in text:\n",
    "        name = unicodedata.name(_text) \n",
    "        if \"CJK UNIFIED\" in name \\\n",
    "        or \"HIRAGANA\" in name \\\n",
    "        or \"KATAKANA\" in name:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_japanese(text_japanese)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "日本語の文章であるため、しっかりと`True`と判定されました。同様に`text_english`でも行ってみましょう。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "no such name",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-fa3291ffca2f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mis_japanese\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_english\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-c2858463beb5>\u001b[0m in \u001b[0;36mis_japanese\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mis_japanese\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_text\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0municodedata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"CJK UNIFIED\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mname\u001b[0m         \u001b[0;32mor\u001b[0m \u001b[0;34m\"HIRAGANA\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mname\u001b[0m         \u001b[0;32mor\u001b[0m \u001b[0;34m\"KATAKANA\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: no such name"
     ]
    }
   ],
   "source": [
    "is_japanese(text_english)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "なぜか英語の文だとうまくいかないみたいなので、このエラーを解決していきましょう。エラーは`name = unicodedata.name(_text) `の部分で起きているため、引数にとっている`_text`が原因ではないかと考えられます。以下のように`print文`で`_text`を出力してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "\n",
    "def is_japanese(text):\n",
    "    for _text in text:\n",
    "        print(_text)\n",
    "        name = unicodedata.name(_text) \n",
    "        if \"CJK UNIFIED\" in name \\\n",
    "        or \"HIRAGANA\" in name \\\n",
    "        or \"KATAKANA\" in name:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "n\n",
      " \n",
      "o\n",
      "p\n",
      "e\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "w\n",
      "i\n",
      "n\n",
      " \n",
      "t\n",
      "h\n",
      "a\n",
      "t\n",
      " \n",
      "f\n",
      "e\n",
      "w\n",
      " \n",
      "s\n",
      "a\n",
      "w\n",
      " \n",
      "c\n",
      "o\n",
      "m\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "h\n",
      "a\n",
      "s\n",
      " \n",
      "g\n",
      "i\n",
      "v\n",
      "e\n",
      "n\n",
      " \n",
      "J\n",
      "a\n",
      "p\n",
      "a\n",
      "n\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "p\n",
      "e\n",
      "r\n",
      "f\n",
      "e\n",
      "c\n",
      "t\n",
      " \n",
      "s\n",
      "t\n",
      "a\n",
      "r\n",
      "t\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "i\n",
      "t\n",
      "s\n",
      " \n",
      "W\n",
      "o\n",
      "r\n",
      "l\n",
      "d\n",
      " \n",
      "C\n",
      "u\n",
      "p\n",
      " \n",
      "c\n",
      "a\n",
      "m\n",
      "p\n",
      "a\n",
      "i\n",
      "g\n",
      "n\n",
      ",\n",
      " \n",
      "b\n",
      "u\n",
      "t\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "r\n",
      "e\n",
      " \n",
      "w\n",
      "i\n",
      "l\n",
      "l\n",
      " \n",
      "b\n",
      "e\n",
      " \n",
      "f\n",
      "u\n",
      "r\n",
      "t\n",
      "h\n",
      "e\n",
      "r\n",
      " \n",
      "h\n",
      "u\n",
      "r\n",
      "d\n",
      "l\n",
      "e\n",
      "s\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "c\n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      " \n",
      "i\n",
      "f\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "t\n",
      "e\n",
      "a\n",
      "m\n",
      " \n",
      "i\n",
      "s\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "b\n",
      "o\n",
      "o\n",
      "k\n",
      " \n",
      "i\n",
      "t\n",
      "s\n",
      " \n",
      "p\n",
      "l\n",
      "a\n",
      "c\n",
      "e\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "k\n",
      "n\n",
      "o\n",
      "c\n",
      "k\n",
      "o\n",
      "u\n",
      "t\n",
      " \n",
      "r\n",
      "o\n",
      "u\n",
      "n\n",
      "d\n",
      ".\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "no such name",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-fa3291ffca2f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mis_japanese\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_english\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-e13072a2776c>\u001b[0m in \u001b[0;36mis_japanese\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_text\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0municodedata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"CJK UNIFIED\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mname\u001b[0m         \u001b[0;32mor\u001b[0m \u001b[0;34m\"HIRAGANA\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mname\u001b[0m         \u001b[0;32mor\u001b[0m \u001b[0;34m\"KATAKANA\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: no such name"
     ]
    }
   ],
   "source": [
    "is_japanese(text_english)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "出力を確認してみると、`.`もしくは、`空白`の影響でエラーが起きている気がします。もう少し詳しくみてみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "\n",
    "def is_japanese(text):\n",
    "    for _text in text:\n",
    "        print(_text+'\\n-----')\n",
    "        name = unicodedata.name(_text)\n",
    "        if \"CJK UNIFIED\" in name \\\n",
    "        or \"HIRAGANA\" in name \\\n",
    "        or \"KATAKANA\" in name:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "-----\n",
      "n\n",
      "-----\n",
      " \n",
      "-----\n",
      "o\n",
      "-----\n",
      "p\n",
      "-----\n",
      "e\n",
      "-----\n",
      "n\n",
      "-----\n",
      "i\n",
      "-----\n",
      "n\n",
      "-----\n",
      "g\n",
      "-----\n",
      " \n",
      "-----\n",
      "w\n",
      "-----\n",
      "i\n",
      "-----\n",
      "n\n",
      "-----\n",
      " \n",
      "-----\n",
      "t\n",
      "-----\n",
      "h\n",
      "-----\n",
      "a\n",
      "-----\n",
      "t\n",
      "-----\n",
      " \n",
      "-----\n",
      "f\n",
      "-----\n",
      "e\n",
      "-----\n",
      "w\n",
      "-----\n",
      " \n",
      "-----\n",
      "s\n",
      "-----\n",
      "a\n",
      "-----\n",
      "w\n",
      "-----\n",
      " \n",
      "-----\n",
      "c\n",
      "-----\n",
      "o\n",
      "-----\n",
      "m\n",
      "-----\n",
      "i\n",
      "-----\n",
      "n\n",
      "-----\n",
      "g\n",
      "-----\n",
      " \n",
      "-----\n",
      "h\n",
      "-----\n",
      "a\n",
      "-----\n",
      "s\n",
      "-----\n",
      " \n",
      "-----\n",
      "g\n",
      "-----\n",
      "i\n",
      "-----\n",
      "v\n",
      "-----\n",
      "e\n",
      "-----\n",
      "n\n",
      "-----\n",
      " \n",
      "-----\n",
      "J\n",
      "-----\n",
      "a\n",
      "-----\n",
      "p\n",
      "-----\n",
      "a\n",
      "-----\n",
      "n\n",
      "-----\n",
      " \n",
      "-----\n",
      "t\n",
      "-----\n",
      "h\n",
      "-----\n",
      "e\n",
      "-----\n",
      " \n",
      "-----\n",
      "p\n",
      "-----\n",
      "e\n",
      "-----\n",
      "r\n",
      "-----\n",
      "f\n",
      "-----\n",
      "e\n",
      "-----\n",
      "c\n",
      "-----\n",
      "t\n",
      "-----\n",
      " \n",
      "-----\n",
      "s\n",
      "-----\n",
      "t\n",
      "-----\n",
      "a\n",
      "-----\n",
      "r\n",
      "-----\n",
      "t\n",
      "-----\n",
      " \n",
      "-----\n",
      "t\n",
      "-----\n",
      "o\n",
      "-----\n",
      " \n",
      "-----\n",
      "i\n",
      "-----\n",
      "t\n",
      "-----\n",
      "s\n",
      "-----\n",
      " \n",
      "-----\n",
      "W\n",
      "-----\n",
      "o\n",
      "-----\n",
      "r\n",
      "-----\n",
      "l\n",
      "-----\n",
      "d\n",
      "-----\n",
      " \n",
      "-----\n",
      "C\n",
      "-----\n",
      "u\n",
      "-----\n",
      "p\n",
      "-----\n",
      " \n",
      "-----\n",
      "c\n",
      "-----\n",
      "a\n",
      "-----\n",
      "m\n",
      "-----\n",
      "p\n",
      "-----\n",
      "a\n",
      "-----\n",
      "i\n",
      "-----\n",
      "g\n",
      "-----\n",
      "n\n",
      "-----\n",
      ",\n",
      "-----\n",
      " \n",
      "-----\n",
      "b\n",
      "-----\n",
      "u\n",
      "-----\n",
      "t\n",
      "-----\n",
      " \n",
      "-----\n",
      "t\n",
      "-----\n",
      "h\n",
      "-----\n",
      "e\n",
      "-----\n",
      "r\n",
      "-----\n",
      "e\n",
      "-----\n",
      " \n",
      "-----\n",
      "w\n",
      "-----\n",
      "i\n",
      "-----\n",
      "l\n",
      "-----\n",
      "l\n",
      "-----\n",
      " \n",
      "-----\n",
      "b\n",
      "-----\n",
      "e\n",
      "-----\n",
      " \n",
      "-----\n",
      "f\n",
      "-----\n",
      "u\n",
      "-----\n",
      "r\n",
      "-----\n",
      "t\n",
      "-----\n",
      "h\n",
      "-----\n",
      "e\n",
      "-----\n",
      "r\n",
      "-----\n",
      " \n",
      "-----\n",
      "h\n",
      "-----\n",
      "u\n",
      "-----\n",
      "r\n",
      "-----\n",
      "d\n",
      "-----\n",
      "l\n",
      "-----\n",
      "e\n",
      "-----\n",
      "s\n",
      "-----\n",
      " \n",
      "-----\n",
      "t\n",
      "-----\n",
      "o\n",
      "-----\n",
      " \n",
      "-----\n",
      "c\n",
      "-----\n",
      "l\n",
      "-----\n",
      "e\n",
      "-----\n",
      "a\n",
      "-----\n",
      "r\n",
      "-----\n",
      " \n",
      "-----\n",
      "i\n",
      "-----\n",
      "f\n",
      "-----\n",
      " \n",
      "-----\n",
      "t\n",
      "-----\n",
      "h\n",
      "-----\n",
      "e\n",
      "-----\n",
      " \n",
      "-----\n",
      "t\n",
      "-----\n",
      "e\n",
      "-----\n",
      "a\n",
      "-----\n",
      "m\n",
      "-----\n",
      " \n",
      "-----\n",
      "i\n",
      "-----\n",
      "s\n",
      "-----\n",
      " \n",
      "-----\n",
      "t\n",
      "-----\n",
      "o\n",
      "-----\n",
      " \n",
      "-----\n",
      "b\n",
      "-----\n",
      "o\n",
      "-----\n",
      "o\n",
      "-----\n",
      "k\n",
      "-----\n",
      " \n",
      "-----\n",
      "i\n",
      "-----\n",
      "t\n",
      "-----\n",
      "s\n",
      "-----\n",
      " \n",
      "-----\n",
      "p\n",
      "-----\n",
      "l\n",
      "-----\n",
      "a\n",
      "-----\n",
      "c\n",
      "-----\n",
      "e\n",
      "-----\n",
      " \n",
      "-----\n",
      "i\n",
      "-----\n",
      "n\n",
      "-----\n",
      " \n",
      "-----\n",
      "t\n",
      "-----\n",
      "h\n",
      "-----\n",
      "e\n",
      "-----\n",
      " \n",
      "-----\n",
      "k\n",
      "-----\n",
      "n\n",
      "-----\n",
      "o\n",
      "-----\n",
      "c\n",
      "-----\n",
      "k\n",
      "-----\n",
      "o\n",
      "-----\n",
      "u\n",
      "-----\n",
      "t\n",
      "-----\n",
      " \n",
      "-----\n",
      "r\n",
      "-----\n",
      "o\n",
      "-----\n",
      "u\n",
      "-----\n",
      "n\n",
      "-----\n",
      "d\n",
      "-----\n",
      ".\n",
      "-----\n",
      "\n",
      "\n",
      "-----\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "no such name",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-fa3291ffca2f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mis_japanese\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_english\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-5a5c57b30706>\u001b[0m in \u001b[0;36mis_japanese\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_text\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_text\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'\\n-----'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0municodedata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"CJK UNIFIED\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mname\u001b[0m         \u001b[0;32mor\u001b[0m \u001b[0;34m\"HIRAGANA\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mname\u001b[0m         \u001b[0;32mor\u001b[0m \u001b[0;34m\"KATAKANA\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: no such name"
     ]
    }
   ],
   "source": [
    "is_japanese(text_english)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "確認してみると、`.`ではなく、`空白`が入ったタイミングでエラーが起きています。実際の文章のどの部分でエラーが起きているのかを確認してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'An opening win that few saw coming has given Japan the perfect start to its World Cup campaign, but there will be further hurdles to clear if the team is to book its place in the knockout round.\\n\\nJapan beat Colombia 2-1 in Saransk on Tuesday in a game of high drama, indelibly shaped by a third-minute handball that saw Colombian midfielder Carlos Sanchez sent off and Shinji Kagawa give Japan the lead from the penalty spot. Colombia clawed its way back to equalize through Juan Quintero’s 39th-minute free kick, but Japan regrouped at halftime and a Yuya Osako header in the 73rd minute gave the Samurai Blue a historic victory.\\n\\nNo Asian team had previously beaten a South American opponent at the World Cup, and few would have predicted that this Japan side would be the one to do it. Results had been poor heading into the tournament, and the Japan Football Association’s decision to replace manager Vahid Halilhodzic with Akira Nishino in April was beginning to look questionable at best.\\n\\nBut Nishino and his players fully deserve their moment after a thoroughly impressive second-half performance against Colombia, and they can now have legitimate ambitions of claiming a place in the second round with games against Senegal and Poland still to come.\\n\\n“Every player has doubts about whether they can perform going into the tournament,” wrote former national team defender Yutaka Akita in Wednesday’s Nikkan Sports. “But I think today’s win will have blown those worries away. I believe that they can write a new page in history with Nishino at the helm.”\\n\\nFortune was certainly in Japan’s favor at Mordovia Arena. First, Colombian playmaker James Rodriguez, who almost single-handedly dismantled Japan during a 4-1 win for the South Americans at the 2014 World Cup, was deemed fit enough only to start on the bench. Then Sanchez blocked Osako’s goal-bound shot with his arm to leave the Colombians a man down with 87 minutes remaining, and Kagawa gratefully dispatched the penalty.\\n\\nThroughout the rest of the first half, however, Japan failed to capitalize on its early present. Takashi Inui and Osako both missed chances that would have surely put the result beyond doubt by halftime, and instead Colombia was allowed to come back into the game and head into the break on level terms.\\n\\n“When the opposition lost a man after only three minutes, you thought ‘we can win this,’ ” wrote former Nadeshiko Japan manager Norio Sasaki in Wednesday’s Sports Nippon. “But actually the team became unsettled. It was a situation that they hadn’t anticipated. So even though they had a numerical advantage, they panicked. They hit meaningless long balls, switched sides and defended too deep, destroying their balance.”\\n\\nFortunately for Japan, things picked up significantly in the second half. The team played with far greater aggression and composure in both attack and defense, and the way Osako took his goal — rising above the Colombian defense to head home a corner — typified the change in attitude.\\n\\nNishino deserves huge credit for the team’s second-half improvement, and a series of canny substitutions further proved the manager’s mettle.\\n\\n“Nishino really proved his ability in getting Japan ready for this first game,” wrote former national team striker Akihiro Nagashima in Wednesday’s Nikkan Sports. “He’s only had a short time in the job, but he’s got the defense working as a unit, and when he brought on (Hotaru) Yamaguchi for (Gaku) Shibasaki and (Shinji) Okazaki for Osako, there was no drop-off in the way the team functioned.”\\n\\nTaking three points from the opening game is undoubtedly a huge advantage for teams at the World Cup, but Japan’s progress to the knockout round is far from assured just yet. Senegal proved it will be a force to be reckoned with after beating Poland 2-1 later on Tuesday, and the Poles and Colombia are by no means out of the reckoning despite their opening losses.\\n\\n“It’s great that the team won, but it wasn’t a controlled victory,” wrote firebrand critic Sergio Echigo in Wednesday’s Nikkan Sports. “They won because they got a penalty and the opposition had a player sent off early in the match. It’s important to analyze things with a clear head and not just celebrate.”\\n\\nAfter the way Nishino and his players suffered in the buildup to the tournament, however, it would take a heart of stone to deny them their moment.'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_english"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "文章を確認してみると、以下の**改行**を表す`\\n`でエラーが起きているのがわかります。\n",
    "![](images/text/12.png)\n",
    "\n",
    "この`\\n`がエラーの原因である可能性が高いため、こちらを**空文字**で置き換えてあげましょう。  \n",
    "※おそらくエスケープシーケンス（`\\n`）にUnicodeネームがないためのエラー"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_japanese(text):\n",
    "    text = text.replace('\\n', '')\n",
    "    for _text in text:\n",
    "        name = unicodedata.name(_text)\n",
    "        if \"CJK UNIFIED\" in name \\\n",
    "        or \"HIRAGANA\" in name \\\n",
    "        or \"KATAKANA\" in name:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_japanese(text_english)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "しっかりと`False`と判定されました！こちらの関数をもとに英語、日本語の両方に対応した要約を行いましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from summpy.lexrank import summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "add_edge() takes 3 positional arguments but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-a8afe41206a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m sentences, debug_info = summarize(\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtext_japanese\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontinuous\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m )\n",
      "\u001b[0;32m/handson/summpy/lexrank.py\u001b[0m in \u001b[0;36msummarize\u001b[0;34m(text, sent_limit, char_limit, imp_require, debug, **lexrank_params)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0mdebug_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msent_splitter_ja\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m     \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msim_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlexrank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mlexrank_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m     \u001b[0msum_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0macc_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/handson/summpy/lexrank.py\u001b[0m in \u001b[0;36mlexrank\u001b[0;34m(sentences, continuous, sim_threshold, alpha, use_divrank, divrank_alpha)\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msim_mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcontinuous\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_edge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'weight'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mranker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mranker_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: add_edge() takes 3 positional arguments but 4 were given"
     ]
    }
   ],
   "source": [
    "sentences, debug_info = summarize(\n",
    "    text_japanese, sent_limit=5, continuous=True, debug=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "エラーが起きてしまいました。こちらは前回最後にデバッグした部分のエラーです。前回の対処法として、`networkx`のバージョンを`1.11`で指定してインストールし直しました。、英語要約の`summa`の裏側では`networkx`が`2.0`で動いているのに対し、日本語要約の`summpy`では、`1.11`で動いている状況です。これをどちらかに揃えないといけないのが今回の課題です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import networkx\n",
    "networkx.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "日本語要約の`summpy`側を`networkx==2.0`で動かすことができないかを考えていきましょう。前回バージョンを下げて対応した**エラー文**と** エラー箇所**を再度確認してみます。\n",
    "\n",
    "![](images/text/13.png)\n",
    "\n",
    "エラー内容である`add_edge() takes 3 positional arguments but 4 were given`は「`add_edge()`関数は`3つの引数`を取るはずなのに、`４つ`与えられてしまっているよ」という内容のエラーです。`add_edge()`の引数は、`i`, `j`, `{'weight': weight}`の３つのはずですが、エラーが起きてしまっています。\n",
    "実際に`networkx`の`add_edge`という関数はどのように引数を取るのが正解であるかがわからないため、`「networkx add_edge」`とGoogleで検索してみましょう。\n",
    "そうすると、以下の記事がヒットするかと思います。  \n",
    "[networkx.Graph.add_edge — NetworkX 2.1 documentation](https://networkx.github.io/documentation/stable/reference/classes/generated/networkx.Graph.add_edge.html)\n",
    "\n",
    "![](images/text/14.png)\n",
    "\n",
    "\n",
    "このドキュメント内の下方に`add_edge()`における引数（`weight`）の指定の仕方が書かれています。\n",
    "\n",
    "![](images/text/15.png)\n",
    "\n",
    "確認してみると`{'weight': weight}`ではなく、`weight=3`のように指定しているのがわかります。そこで`summpy/lexrank.py`の８５行目引数の部分を以下のように変更し、保存しましょう。\n",
    "\n",
    "![](images/text/16.png)\n",
    "\n",
    "一度`Jupyter notebook`をシャットダウンし、もう一度実行してみてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences, debug_info = summarize(\n",
    "    text_japanese, sent_limit=5, continuous=True, debug=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "エラーが起きずに実行されたかと思います。要約された文章がしっかり入っているか確認してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "その時にできた最初のセミナーが『人工知能・機械学習 脱ブラックボックスセミナー』です。\n",
      "そこから、7月19日の初回セミナーに向け、企画からカリキュラム作成（PFNの方のレビューまでいただきました）、チラシ作成、現場のオペレーション整備など、人生初めての協業でわからないことだらけでしたが、多くの方に助けてもらいながら、がむしゃらに夜遅くまで働き続け、なんとか記念すべき第１回目のセミナーを迎えることができました。\n",
      "７月からはじまったDeep Learning ハンズオンセミナーが一段落して、今西くんにセミナー講義も任せられるようになり、時間に余裕ができたため、他の人からお話を頂いていたイベント登壇やセミナー協業を進めていきました。\n",
      "上記のセミナーもオフラインで脱ブラックボックスセミナーを行う中で受講生からでてきた要望であり、現場の意見を取り入れたとても良い内容となりました。\n",
      "ただし、２日間のセミナー内容のカリキュラム作成は非常に大変であり、各セミナーごとに企画からセミナー開始まで約１ヶ月ずつかかり、こちらもなんとか時間がない中で合間を縫って作成し続けました。\n"
     ]
    }
   ],
   "source": [
    "for sent in sentences:\n",
    "    print(sent.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "しっかりと要約できているのが確認できました。それでは、本題である**「英語と日本語に対応する文章要約」**に戻りましょう。  \n",
    "一旦、引数のパラメータの値は固定して実装していきます。\n",
    "####  日本語の場合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['その時にできた最初のセミナーが『人工知能・機械学習 脱ブラックボックスセミナー』です。\\n\\n', 'そこから、7月19日の初回セミナーに向け、企画からカリキュラム作成（PFNの方のレビューまでいただきました）、チラシ作成、現場のオペレーション整備など、人生初めての協業でわからないことだらけでしたが、多くの方に助けてもらいながら、がむしゃらに夜遅くまで働き続け、なんとか記念すべき第１回目のセミナーを迎えることができました。\\n\\n', '７月からはじまったDeep Learning ハンズオンセミナーが一段落して、今西くんにセミナー講義も任せられるようになり、時間に余裕ができたため、他の人からお話を頂いていたイベント登壇やセミナー協業を進めていきました。\\n\\n', '上記のセミナーもオフラインで脱ブラックボックスセミナーを行う中で受講生からでてきた要望であり、現場の意見を取り入れたとても良い内容となりました。\\n', 'ただし、２日間のセミナー内容のカリキュラム作成は非常に大変であり、各セミナーごとに企画からセミナー開始まで約１ヶ月ずつかかり、こちらもなんとか時間がない中で合間を縫って作成し続けました。\\n\\n']\n"
     ]
    }
   ],
   "source": [
    "text = text_japanese\n",
    "\n",
    "if is_japanese(text):\n",
    "    sentences, debug_info = summarize(\n",
    "    text_japanese, sent_limit=5, continuous=True, debug=True\n",
    "    )\n",
    "    print(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "####  英語の場合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "lexrank() got an unexpected keyword argument 'words'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-ca5ed25b4b77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#英語の場合\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0msummarize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/handson/summpy/lexrank.py\u001b[0m in \u001b[0;36msummarize\u001b[0;34m(text, sent_limit, char_limit, imp_require, debug, **lexrank_params)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0mdebug_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msent_splitter_ja\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m     \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msim_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlexrank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mlexrank_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m     \u001b[0msum_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0macc_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: lexrank() got an unexpected keyword argument 'words'"
     ]
    }
   ],
   "source": [
    "text = text_english\n",
    "\n",
    "# 日本語の場合\n",
    "if is_japanese(text):\n",
    "    sentences, debug_info = summarize(\n",
    "    text_japanese, sent_limit=5, continuous=True, debug=True\n",
    "    )\n",
    "    print(sentences)\n",
    "#英語の場合    \n",
    "else:\n",
    "    summarize(text, words=50,  split=True)\n",
    "    print(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "先程と同様に行ったのですが、エラーが起きてしまいました。今回の原因は、日本語要約`summpy`側の関数名が`summarize`であり、英語要約`summa`側の関数も`summarize`であることが原因です。そのため、以下のように修正しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from summa.summarizer import summarize\n",
    "from summa import summarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['“Nishino really proved his ability in getting Japan ready for this first game,” wrote former national team striker Akihiro Nagashima in Wednesday’s Nikkan Sports.', 'Taking three points from the opening game is undoubtedly a huge advantage for teams at the World Cup, but Japan’s progress to the knockout round is far from assured just yet.']\n"
     ]
    }
   ],
   "source": [
    "text = text_english\n",
    "\n",
    "# 日本語の場合\n",
    "if is_japanese(text):\n",
    "    sentences, debug_info = summarize(\n",
    "    text_japanese, sent_limit=5, continuous=True, debug=True\n",
    "    )\n",
    "    print(sentences)\n",
    "#英語の場合    \n",
    "else:\n",
    "    sentences = summarizer.summarize(text, words=50,  split=True)\n",
    "    print(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "これで日本語と英語の両方に対応させることができたため、関数化しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_summary(text):\n",
    "\n",
    "    # 日本語の場合\n",
    "    if is_japanese(text):\n",
    "        sentences, debug_info = summarize(\n",
    "        text_japanese, sent_limit=5, continuous=True, debug=True\n",
    "        )\n",
    "    #英語の場合    \n",
    "    else:\n",
    "        sentences = summarizer.summarize(text, words=50,  split=True)\n",
    "    \n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['その時にできた最初のセミナーが『人工知能・機械学習 脱ブラックボックスセミナー』です。\\n\\n',\n",
       " 'そこから、7月19日の初回セミナーに向け、企画からカリキュラム作成（PFNの方のレビューまでいただきました）、チラシ作成、現場のオペレーション整備など、人生初めての協業でわからないことだらけでしたが、多くの方に助けてもらいながら、がむしゃらに夜遅くまで働き続け、なんとか記念すべき第１回目のセミナーを迎えることができました。\\n\\n',\n",
       " '７月からはじまったDeep Learning ハンズオンセミナーが一段落して、今西くんにセミナー講義も任せられるようになり、時間に余裕ができたため、他の人からお話を頂いていたイベント登壇やセミナー協業を進めていきました。\\n\\n',\n",
       " '上記のセミナーもオフラインで脱ブラックボックスセミナーを行う中で受講生からでてきた要望であり、現場の意見を取り入れたとても良い内容となりました。\\n',\n",
       " 'ただし、２日間のセミナー内容のカリキュラム作成は非常に大変であり、各セミナーごとに企画からセミナー開始まで約１ヶ月ずつかかり、こちらもなんとか時間がない中で合間を縫って作成し続けました。\\n\\n']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_summary(text_japanese)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['“Nishino really proved his ability in getting Japan ready for this first game,” wrote former national team striker Akihiro Nagashima in Wednesday’s Nikkan Sports.',\n",
       " 'Taking three points from the opening game is undoubtedly a huge advantage for teams at the World Cup, but Japan’s progress to the knockout round is far from assured just yet.']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_summary(text_english)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pythonファイルからの読み込み\n",
    "上記で作成した`get_summary`を別のPythonファイルに移し、そのPythonファイルを読みこむことで、関数を呼び出してください。Pythonファイルの名前は、`summary.py`にしましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from summary import get_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['その時にできた最初のセミナーが『人工知能・機械学習 脱ブラックボックスセミナー』です。\\n\\n',\n",
       " 'そこから、7月19日の初回セミナーに向け、企画からカリキュラム作成（PFNの方のレビューまでいただきました）、チラシ作成、現場のオペレーション整備など、人生初めての協業でわからないことだらけでしたが、多くの方に助けてもらいながら、がむしゃらに夜遅くまで働き続け、なんとか記念すべき第１回目のセミナーを迎えることができました。\\n\\n',\n",
       " '７月からはじまったDeep Learning ハンズオンセミナーが一段落して、今西くんにセミナー講義も任せられるようになり、時間に余裕ができたため、他の人からお話を頂いていたイベント登壇やセミナー協業を進めていきました。\\n\\n',\n",
       " '上記のセミナーもオフラインで脱ブラックボックスセミナーを行う中で受講生からでてきた要望であり、現場の意見を取り入れたとても良い内容となりました。\\n',\n",
       " 'ただし、２日間のセミナー内容のカリキュラム作成は非常に大変であり、各セミナーごとに企画からセミナー開始まで約１ヶ月ずつかかり、こちらもなんとか時間がない中で合間を縫って作成し続けました。\\n\\n']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_summary(text_japanese)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['“Nishino really proved his ability in getting Japan ready for this first game,” wrote former national team striker Akihiro Nagashima in Wednesday’s Nikkan Sports.',\n",
       " 'Taking three points from the opening game is undoubtedly a huge advantage for teams at the World Cup, but Japan’s progress to the knockout round is far from assured just yet.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_summary(text_english)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "上記のようにインポートできたら成功です。`summary.py`のコードは以下になります。\n",
    "\n",
    "```python\n",
    "import unicodedata\n",
    "from summpy.lexrank import summarize\n",
    "from summa import summarizer\n",
    "\n",
    "def is_japanese(text):\n",
    "    text = text.replace('\\n', '')\n",
    "    for _text in text:\n",
    "        name = unicodedata.name(_text)\n",
    "        if \"CJK UNIFIED\" in name \n",
    "        or \"HIRAGANA\" in name \n",
    "        or \"KATAKANA\" in name:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def get_summary(text):\n",
    "    # 日本語の場合\n",
    "    if is_japanese(text):\n",
    "        sentences, debug_info = summarize(\n",
    "        text, sent_limit=5, continuous=True, debug=True\n",
    "        )\n",
    "    #英語の場合    \n",
    "    else:\n",
    "        sentences = summarizer.summarize(text, words=50,  split=True)\n",
    "    \n",
    "    return sentences\n",
    " ```\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3週目\n",
    "\n",
    "\n",
    "### 文章要約モデルをアプリに埋め込む\n",
    "\n",
    "#### 必要なページ\n",
    "\n",
    "今回は大きく分けて以下の２つのページで構成されています。\n",
    "- TOPページ\n",
    "- 要約後のページ\n",
    "\n",
    "##### TOPページ（index.html）\n",
    "\n",
    "![](images/text/17.png)\n",
    "\n",
    "\n",
    "##### 要約後のページ（summary.html）\n",
    "\n",
    "![](images/text/18.png)\n",
    "\n",
    "\n",
    "##### 扱うライブラリ\n",
    "\n",
    "\n",
    "`Materialize.css`を使用してレイアウトなどを整えていきます。  \n",
    "[Materialize.css](https://materializecss.com/)\n",
    "\n",
    "これは個人の好みの問題なので、`Bootstrap`等を使用しても大丈夫です。\n",
    "\n",
    "前回同様Dockerを使用して作成していくのがスムーズかもしれません。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TOPページの作成\n",
    "\n",
    "#### index.html\n",
    "\n",
    "```html\n",
    "\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "\n",
    "<head>\n",
    "  <!--Import Google Icon Font-->\n",
    "  <link href=\"https://fonts.googleapis.com/icon?family=Material+Icons\" rel=\"stylesheet\">\n",
    "  <!--Import materialize.css-->\n",
    "  <!-- Compiled and minified CSS -->\n",
    "  <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/materialize/1.0.0-rc.2/css/materialize.min.css\">\n",
    "\n",
    "  <meta charset=\"utf-8\">\n",
    "  <title>文章要約</title>\n",
    "  <link rel=\"stylesheet\" href=\"static/css/index.css\">\n",
    "</head>\n",
    "\n",
    "<body>\n",
    "  <div class=\"row\">\n",
    "    <!-- header -->\n",
    "    <header class=\"col s12 teal lighten-1\">\n",
    "      <div class=\"col s12 offset-s1\">\n",
    "        <a href=\"/\"><p class=\"white-text\">文章要約アプリ</p></a>\n",
    "      </div>\n",
    "    </header>\n",
    "\n",
    "    <div class=\"input_text input-field col s5 offset-s1\">\n",
    "      <form id=\"summarize\" action=\"/\" method=post enctype=multipart/form-data>\n",
    "        <div class=\"input_text input-field\">\n",
    "          <textarea name=\"text\" class=\"materialize-textarea\"></textarea>\n",
    "          <label for=\"textarea1\">Type text you want to summarize</label>\n",
    "        </div>\n",
    "        <div class=\"col s2 offset-s9\">\n",
    "          <button class=\"btn waves-effect waves-light\" form=\"summarize\" type=\"submit\" name=\"summarize\" value=Summarize>Summarize\n",
    "          </button>\n",
    "        </div>\n",
    "      </form>\n",
    "    </div>\n",
    "\n",
    "    <div class=\"output_summary input-field col s5\">\n",
    "      <div class=\"input_text input-field\">\n",
    "        <textarea id=\"textarea1\" class=\"materialize-textarea\" disabled>\n",
    "      </textarea>\n",
    "        <label for=\"textarea1\">Summary</label>\n",
    "      </div>\n",
    "    </div>\n",
    "    <div class=\"col s1\">\n",
    "    </div>\n",
    "  </div>\n",
    "\n",
    "</body>\n",
    "\n",
    "</html>\n",
    "```\n",
    "\n",
    "\n",
    "```html\n",
    "  <!-- Compiled and minified CSS -->\n",
    "  <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/materialize/1.0.0-rc.2/css/materialize.min.css\">\n",
    "```\n",
    "\n",
    "上記の部分で、`materialize.min.css`をCDN経由で読み込んでいます。\n",
    "\n",
    "\n",
    "レイアウトは、以下の`Grid`の部分を参考に行っています。基本的には大枠に`class=\"row\"`を付与し、その中身に`class=\"col s6\"`などと書き、**１２カラム**に分割し考えています。\n",
    "\n",
    "[](https://materializecss.com/grid.html)\n",
    "\n",
    "\n",
    "```html\n",
    "    <header class=\"col s12 teal lighten-1\">\n",
    "      <div class=\"col s12 offset-s1\">\n",
    "        <a href=\"/\"><p class=\"white-text\">文章要約アプリ</p></a>\n",
    "      </div>\n",
    "    </header>\n",
    "```\n",
    "こちらが`header`部分になります。ヘッダー部分をクリックすると、**TOPページ**に移行します。\n",
    "\n",
    "\n",
    "```html\n",
    "    <div class=\"input_text input-field col s5 offset-s1\">\n",
    "      <form id=\"summarize\" action=\"/\" method=post enctype=multipart/form-data>\n",
    "        <div class=\"input_text input-field\">\n",
    "          <textarea name=\"text\" class=\"materialize-textarea\"></textarea>\n",
    "          <label for=\"textarea1\">Type text you want to summarize</label>\n",
    "        </div>\n",
    "        <div class=\"col s2 offset-s9\">\n",
    "          <button class=\"btn waves-effect waves-light\" form=\"summarize\" type=\"submit\" name=\"summarize\" value=Summarize>Summarize\n",
    "          </button>\n",
    "        </div>\n",
    "      </form>\n",
    "    </div>\n",
    "```\n",
    "こちらが要約したいテキストを表示する部分になります。以下のサイトを参考にしつつ、フォームを作成しました。\n",
    "\n",
    "https://materializecss.com/text-inputs.html\n",
    "\n",
    "```html\n",
    "    <div class=\"output_summary input-field col s5\">\n",
    "      <div class=\"input_text input-field\">\n",
    "        <textarea id=\"textarea1\" class=\"materialize-textarea\" disabled>\n",
    "      </textarea>\n",
    "        <label for=\"textarea1\">Summary</label>\n",
    "      </div>\n",
    "    </div>\n",
    "    <div class=\"col s1\">\n",
    "    </div>\n",
    "```\n",
    "上記は、要約した文章を入れる部分になります。まだ記述していないですが、後々、`app.py`から渡される要約結果を表示します。\n",
    "\n",
    "\n",
    "#### app.py\n",
    "\n",
    "```python\n",
    "# coding: utf-8\n",
    "from flask import Flask, render_template, request, redirect, url_for\n",
    "\n",
    "# app という名前でFlaskオブジェクトをインスタンス化\n",
    "app = Flask(__name__)\n",
    "\n",
    "# rootディレクトリにアクセスした場合の挙動\n",
    "@app.route('/', methods=['GET', 'POST'])\n",
    "def index():\n",
    "    return render_template(\"index.html\")\n",
    "\n",
    "# --- メインで実行される関数 ---\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(host=\"0.0.0.0\", port=5000, debug=True)\n",
    "```\n",
    "\n",
    "こちらはいつもどおりFlaskの基本的な部分となっております。\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 要約後のページ\n",
    "\n",
    "#### summary.html\n",
    "\n",
    "```html\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "\n",
    "<head>\n",
    "  <!--Import Google Icon Font-->\n",
    "  <link href=\"https://fonts.googleapis.com/icon?family=Material+Icons\" rel=\"stylesheet\">\n",
    "  <!--Import materialize.css-->\n",
    "  <!-- Compiled and minified CSS -->\n",
    "  <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/materialize/1.0.0-rc.2/css/materialize.min.css\">\n",
    "  <meta charset=\"utf-8\">\n",
    "  <title>文章要約</title>\n",
    "</head>\n",
    "\n",
    "<body>\n",
    "  <div class=\"row\">\n",
    "    <!-- header -->\n",
    "    <header class=\"col s12 teal lighten-1\">\n",
    "      <div class=\"col s12 offset-s1\">\n",
    "        <a href=\"/\"><p class=\"white-text\">文章要約アプリ</p></a>\n",
    "      </div>\n",
    "    </header>\n",
    "\n",
    "    <div class=\"input_text input-field col s5 offset-s1\">\n",
    "      <form id=\"summarize\" action=\"/\" method=post enctype=multipart/form-data>\n",
    "        <div class=\"input_text input-field\">\n",
    "          <textarea name=\"text\" class=\"materialize-textarea\"></textarea>\n",
    "          <label for=\"textarea1\">Type text you want to summarize</label>\n",
    "        </div>\n",
    "        <div class=\"col s2 offset-s9\">\n",
    "          <button class=\"btn waves-effect waves-light\" form=\"summarize\" type=\"submit\" name=\"summarize\" value=Summarize>Summarize\n",
    "          </button>\n",
    "        </div>\n",
    "      </form>\n",
    "    </div>\n",
    "\n",
    "    <div class=\"output_summary input-field col s5\">\n",
    "      <div class=\"input_text input-field\">\n",
    "        <textarea id=\"textarea1\" class=\"materialize-textarea\" disabled>\n",
    "        {% for summary in summaries %}\n",
    "        {{summary.replace('\\r', '').replace('\\n', '')}}\n",
    "        {% endfor %}\n",
    "      </textarea>\n",
    "        <label for=\"textarea1\">Summary</label>\n",
    "      </div>\n",
    "    </div>\n",
    "    <div class=\"col s1\">\n",
    "    </div>\n",
    "  </div>\n",
    "\n",
    "</body>\n",
    "\n",
    "</html>\n",
    "\n",
    "```\n",
    "\n",
    "`index.html`に加えて変更した点は最後の以下の部分です。`app.py`から引き渡される変数`summaries`をfor文で１文ずつ取得しています。その際に、無駄なエスケープシーケンスが多く含まれているので`replace`を用いて除去します。\n",
    "\n",
    "\n",
    "```html\n",
    "    <div class=\"output_summary input-field col s5\">\n",
    "      <div class=\"input_text input-field\">\n",
    "        <textarea id=\"textarea1\" class=\"materialize-textarea\" disabled>\n",
    "        {% for summary in summaries %}\n",
    "        {{summary.replace('\\r', '').replace('\\n', '')}}\n",
    "        {% endfor %}\n",
    "      </textarea>\n",
    "        <label for=\"textarea1\">Summary</label>\n",
    "      </div>\n",
    "    </div>\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### ファイル階層\n",
    "\n",
    "文章要約に必要な`summary.py(前回作成済み)`と`summpy`フォルダを`app.py`と同じ階層に配置します。\n",
    "\n",
    "```bash\n",
    ".\n",
    "├── __pycache__\n",
    "│   └── summary.cpython-36.pyc\n",
    "├── app.py\n",
    "├── static\n",
    "├── summary.py\n",
    "├── summpy\n",
    "│   ├── __init__.py\n",
    "│   ├── __pycache__\n",
    "│   │   ├── __init__.cpython-36.pyc\n",
    "│   │   ├── lexrank.cpython-36.pyc\n",
    "│   │   └── tools.cpython-36.pyc\n",
    "│   ├── lexrank.py\n",
    "│   ├── mcp_summ.py\n",
    "│   ├── misc\n",
    "│   │   ├── __init__.py\n",
    "│   │   ├── __pycache__\n",
    "│   │   │   ├── __init__.cpython-36.pyc\n",
    "│   │   │   ├── divrank.cpython-36.pyc\n",
    "│   │   │   └── mecab_segmenter.cpython-36.pyc\n",
    "│   │   ├── divrank.py\n",
    "│   │   ├── janome_segmenter.py\n",
    "│   │   └── mecab_segmenter.py\n",
    "│   ├── server.py\n",
    "│   ├── server_data\n",
    "│   │   └── test.html\n",
    "│   └── tools.py\n",
    "└── templates\n",
    "    ├── index.html\n",
    "    └── summary.html\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "#### app.py\n",
    "\n",
    "```python\n",
    "# coding: utf-8\n",
    "from flask import Flask, render_template, request, redirect, url_for\n",
    "# 追加\n",
    "from summary import get_summary\n",
    "\n",
    "# app という名前でFlaskオブジェクトをインスタンス化\n",
    "app = Flask(__name__)\n",
    "\n",
    "# rootディレクトリにアクセスした場合の挙動\n",
    "@app.route('/', methods=['GET', 'POST'])\n",
    "def index():\n",
    "    if request.method == 'POST':\n",
    "        text = request.form['text']\n",
    "        summaries  = get_summary(text)\n",
    "        return render_template(\"summary.html\", summaries=summaries)\n",
    "\n",
    "    return render_template(\"index.html\")\n",
    "\n",
    "# --- メインで実行される関数 ---\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(host=\"0.0.0.0\", port=5000, debug=True)\n",
    "\n",
    "```\n",
    "\n",
    "最初に追加した部分は、`summary`のimport部分です。\n",
    "\n",
    "```python\n",
    "from summary import get_summary\n",
    "```\n",
    "\n",
    "\n",
    "```python\n",
    "def index():\n",
    "    if request.method == 'POST':\n",
    "        text = request.form['text']\n",
    "        summaries  = get_summary(text)\n",
    "        return render_template(\"summary.html\", summaries=summaries)\n",
    "\n",
    "    return render_template(\"index.html\")\n",
    "```\n",
    "\n",
    "`index.html`からテキストが`POST`されたら、そのテキストを読み込み`text`という変数に代入しています。その`text`を`get_summary（）`に渡し、その要約結果`summaries`を`summary.html`に渡しています。\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 発展課題\n",
    "上記を終えた方は以下のような課題に取り組んでみるのも面白いと思います。\n",
    "\n",
    "- レイアウトのブラッシュアップ\n",
    "- 多言語対応\n",
    "- 要約時のパラメータも調整可能\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ４週目\n",
    "\n",
    "### 本日行うこと\n",
    "- アカウント作成 (Docker Hub & Micrsoft Azure)\n",
    "- Dockerイメージの作成＆プッシュ\n",
    "- Azure上にデプロイ\n",
    "\n",
    "\n",
    "### アカウント登録\n",
    "\n",
    "#### DockerHub\n",
    "以下のサイトにてアカウントの登録を行ってください。  \n",
    "https://hub.docker.com/\n",
    "\n",
    "\n",
    "#### Microsoft Azure\n",
    "すでにアカウント作成済みであると思いますが、アカウントを持っていない方は以下のサイトにてアカウントの登録を行ってください。　　\n",
    "https://azure.microsoft.com/ja-jp/\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dcokerイメージの作成＆プッシュ\n",
    "以下のGithubを参考に、先週作成した文章要約アプリがコンテナ作成時（`run`）に立ち上がるようにしてください。  \n",
    "https://github.com/Azure-App-Service/flask-docker\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Webアプリの修正\n",
    "\n",
    "上記のGithubのコードに先週作成したコードを当てはめていきます。\n",
    "\n",
    "##### ディレクトリ階層\n",
    "```\n",
    ".\n",
    "├── Dockerfile\n",
    "├── LICENSE\n",
    "├── README.md\n",
    "├── flaskwebapp\n",
    "│   ├── __init__.py\n",
    "│   ├── __init__.pyc\n",
    "│   ├── __pycache__\n",
    "│   ├── static\n",
    "│   ├── summary.py\n",
    "│   ├── summpy\n",
    "│   ├── templates\n",
    "│   └── views.py\n",
    "├── init.sh\n",
    "├── requirements.txt\n",
    "├── runserver.py\n",
    "└── sshd_config\n",
    "```\n",
    "\n",
    "##### Dockerfile\n",
    "```\n",
    "FROM kikagaku/handson:v3.0\n",
    "\n",
    "RUN mkdir /code\n",
    "WORKDIR /code\n",
    "ADD requirements.txt /code/\n",
    "RUN pip install -r requirements.txt\n",
    "ADD . /code/\n",
    "\n",
    "# ssh\n",
    "ENV SSH_PASSWD \"root:kikagaku\"\n",
    "RUN apt-get update \\\n",
    "        && apt-get install -y --no-install-recommends dialog \\\n",
    "        && apt-get update \\\n",
    "\t&& apt-get install -y --no-install-recommends openssh-server \\\n",
    "\t&& echo \"$SSH_PASSWD\" | chpasswd\n",
    "\n",
    "COPY sshd_config /etc/ssh/\n",
    "COPY init.sh /usr/local/bin/\n",
    "\n",
    "RUN chmod u+x /usr/local/bin/init.sh\n",
    "EXPOSE 5000 2222\n",
    "ENTRYPOINT [\"init.sh\"]\n",
    "```\n",
    "\n",
    "変更部分は2点あります。\n",
    "1. Baseイメージの変更\n",
    "以下のBaseとなるイメージの変更です。`python`ではなく、`kikagaku/handson:v3.0`をもとに作成します。  \n",
    "`FROM kikagaku/handson:v3.0`\n",
    "2. パスワードの変更\n",
    "SSHでアクセスする際のパスワードを変更します。  \n",
    "`ENV SSH_PASSWD \"root:kikagaku\"`\n",
    "\n",
    "\n",
    "##### views.py\n",
    "```python\n",
    "\"\"\"\n",
    "Routes and views for the flask application.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "from flask import Flask, render_template, request, redirect, url_for\n",
    "\n",
    "from flaskwebapp import app\n",
    "from flaskwebapp.summary import get_summary\n",
    "\n",
    "# rootディレクトリにアクセスした場合の挙動\n",
    "@app.route('/', methods=['GET', 'POST'])\n",
    "def index():\n",
    "    if request.method == 'POST':\n",
    "        text = request.form['text']\n",
    "        summaries  = get_summary(text)\n",
    "\n",
    "        return render_template(\"summary.html\", summaries=summaries)\n",
    "\n",
    "    return render_template(\"index.html\")\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "##### requirements.txt\n",
    "必要なライブラリ類を記載します。\n",
    "```text\n",
    "Flask==0.12.1\n",
    "Jinja2==2.9.6\n",
    "Werkzeug==0.12.1\n",
    "networkx==2.1\n",
    "multiqc==1.2\n",
    "summa==1.0.0\n",
    "```\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### summary.py\n",
    "\n",
    "```python\n",
    "import unicodedata\n",
    "# 修正\n",
    "from flaskwebapp.summpy.lexrank import summarize\n",
    "from summa import summarizer\n",
    "\n",
    "def is_japanese(text):\n",
    "    text = text.replace('\\r', '').replace('\\n', '')\n",
    "    for _text in text:\n",
    "        name = unicodedata.name(_text)\n",
    "        if \"CJK UNIFIED\" in name \\\n",
    "        or \"HIRAGANA\" in name \\\n",
    "        or \"KATAKANA\" in name:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def get_summary(text):\n",
    "    # 日本語の場合\n",
    "    if is_japanese(text):\n",
    "        sentences, debug_info = summarize(\n",
    "        text, sent_limit=5, continuous=True, debug=True\n",
    "        )\n",
    "    #英語の場合\n",
    "    else:\n",
    "        sentences = summarizer.summarize(text, words=50, split=True)\n",
    "\n",
    "    return sentences\n",
    "```\n",
    "\n",
    "##### __init__.py\n",
    "```python\n",
    "\"\"\"\n",
    "The flask application package.\n",
    "\"\"\"\n",
    "\n",
    "from flask import Flask\n",
    "app = Flask(__name__)\n",
    "\n",
    "import flaskwebapp.views\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dockerイメージの作成\n",
    "修正を加えた上記のアプリケーションを`イメージ化`しましょう。\n",
    "\n",
    "`Dockerfile`がある階層で、以下のコマンドを打ちます。` <docker-id>`の部分がご自身の`Docker ID`を入力してください。\n",
    "\n",
    "```bash\n",
    "docker build --tag <docker-id>/flask-docker:v1.0.0 .\n",
    "```\n",
    "\n",
    "上記は以下を意味します。\n",
    "```bash\n",
    "docker build --tag <docker-id>/<イメージ名>:タグ .\n",
    "```\n",
    "以下のような状態になっていれば成功です。イメージを作成中です。\n",
    "![](images/text/23.png)\n",
    "\n",
    "\n",
    "\n",
    "#### コンテナ作成  \n",
    "\n",
    "作成したイメージをもとにコンテナを作成しましょう。`run`のタイミングで、アプリケーションが起動すれば成功です。\n",
    "```bash\n",
    "docker run -it -p 5000:5000 <docker-id>/flask-docker:v1.0.0\n",
    "```\n",
    "![](images/text/24.png)\n",
    "\n",
    "http://0.0.0.0:5000/　にアクセスしてみましょう。最初は少し時間がかかるかもしれません。\n",
    "\n",
    "\n",
    "#### Docker Hubにイメージをプッシュ\n",
    "\n",
    "##### Dockerにログイン\n",
    "まずは、Dockerにログインしましょう。\n",
    "\n",
    "```bash\n",
    "docker login --username <docker-id>\n",
    "```\n",
    "\n",
    "![](images/text/19.png)\n",
    "\n",
    "##### イメージをプッシュ\n",
    "\n",
    "それでは、DockerHub上にイメージをプッシュしましょう。以下のコマンドで簡単に行うことができます。\n",
    "```bash\n",
    "docker push <docker-id>/flask-docker:v1.0.0\n",
    "```\n",
    "\n",
    "![](images/text/20.png)\n",
    "\n",
    "\n",
    "しっかりとプッシュされたか確認しましょう。\n",
    "\n",
    "\n",
    "![](images/text/25.png)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Azure上にデプロイ\n",
    "\n",
    "\n",
    "さきほど作成したDockerイメージAzure上にデプロイしましょう。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "リソースの作成\n",
    "\n",
    "\n",
    "![](images/text/26.png)\n",
    "\n",
    "\n",
    "\n",
    "**「Web App  on Linux」**と検索\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "![](images/text/27.png)\n",
    "\n",
    "![](images/text/28.png)\n",
    "\n",
    "App Serviceプランの作成\n",
    "\n",
    "\n",
    "![](images/text/29.png)\n",
    "\n",
    "![](images/text/30.png)\n",
    "\n",
    "\n",
    "今回は一番安い**開発/テスト**用の価格で作成しましょう。\n",
    "\n",
    "![](images/text/31.png)\n",
    "\n",
    "![](images/text/32.png)\n",
    "\n",
    "![](images/text/33.png)\n",
    "\n",
    "\n",
    "![](images/text/34.png)\n",
    "\n",
    "最後に一番下の**「作成」**ボタンを押してください。\n",
    "\n",
    "\n",
    "#### ポートの開放\n",
    "\n",
    "\n",
    "![](images/text/35.png)\n",
    "\n",
    "![](images/text/36.png)\n",
    "\n",
    "![](images/text/37.png)\n",
    "\n",
    "\n",
    "以下のURLにアクセスし、アプリケーションが立ち上がっていればデプロイ成功です。最初はアプリ起動までに時間がかかります。\n",
    "\n",
    "![](images/text/38.png)\n",
    "\n",
    "![](images/text/39.png)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "無事にデプロイが完了しました。`Web App on Linux`を用いると簡単にDocker環境をそのままデプロイすることができます。\n",
    "\n",
    "**補足**  \n",
    "継続的なデプロイを行いたい方は以下のURLを参考にDockerHubとAzureの紐づけを行ってください。  \n",
    "https://docs.microsoft.com/ja-jp/azure/app-service/containers/app-service-linux-ci-cd\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
